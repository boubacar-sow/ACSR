{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = r\"C:\\Users\\bouba\\OneDrive\\Documents\\ACSR\\ACSR\\output\\extracted_features_mp4\"\n",
    "annotations_dir = r\"C:\\Users\\bouba\\OneDrive\\Documents\\ACSR\\ACSR\\output\\annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn_video</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>distance_face130_r_hand8</th>\n",
       "      <th>tan_angle_face130_r_hand8</th>\n",
       "      <th>distance_face152_r_hand8</th>\n",
       "      <th>tan_angle_face152_r_hand8</th>\n",
       "      <th>distance_face94_r_hand8</th>\n",
       "      <th>tan_angle_face94_r_hand8</th>\n",
       "      <th>distance_face130_r_hand9</th>\n",
       "      <th>tan_angle_face130_r_hand9</th>\n",
       "      <th>...</th>\n",
       "      <th>acceleration_x_r_hand8</th>\n",
       "      <th>acceleration_y_r_hand8</th>\n",
       "      <th>velocity_x_r_hand9</th>\n",
       "      <th>velocity_y_r_hand9</th>\n",
       "      <th>acceleration_x_r_hand9</th>\n",
       "      <th>acceleration_y_r_hand9</th>\n",
       "      <th>velocity_x_r_hand12</th>\n",
       "      <th>velocity_y_r_hand12</th>\n",
       "      <th>acceleration_x_r_hand12</th>\n",
       "      <th>acceleration_y_r_hand12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>22</td>\n",
       "      <td>4.544161</td>\n",
       "      <td>0.215778</td>\n",
       "      <td>2.993590</td>\n",
       "      <td>0.198311</td>\n",
       "      <td>3.952022</td>\n",
       "      <td>0.148803</td>\n",
       "      <td>5.012093</td>\n",
       "      <td>0.068935</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>23</td>\n",
       "      <td>4.432777</td>\n",
       "      <td>0.226310</td>\n",
       "      <td>2.886811</td>\n",
       "      <td>0.213178</td>\n",
       "      <td>3.815771</td>\n",
       "      <td>0.157548</td>\n",
       "      <td>5.075631</td>\n",
       "      <td>0.046591</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016066</td>\n",
       "      <td>0.009251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009077</td>\n",
       "      <td>-0.019512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>24</td>\n",
       "      <td>4.395037</td>\n",
       "      <td>0.227604</td>\n",
       "      <td>2.859063</td>\n",
       "      <td>0.215205</td>\n",
       "      <td>3.769736</td>\n",
       "      <td>0.158046</td>\n",
       "      <td>5.071182</td>\n",
       "      <td>0.037993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003090</td>\n",
       "      <td>0.012441</td>\n",
       "      <td>-0.006354</td>\n",
       "      <td>-0.001570</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>-0.010821</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>-0.008381</td>\n",
       "      <td>0.019263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>25</td>\n",
       "      <td>2.349447</td>\n",
       "      <td>0.122057</td>\n",
       "      <td>0.855116</td>\n",
       "      <td>-0.115871</td>\n",
       "      <td>1.760024</td>\n",
       "      <td>-0.052596</td>\n",
       "      <td>3.514490</td>\n",
       "      <td>-0.052680</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099307</td>\n",
       "      <td>-0.273851</td>\n",
       "      <td>-0.055388</td>\n",
       "      <td>-0.227089</td>\n",
       "      <td>-0.049035</td>\n",
       "      <td>-0.225518</td>\n",
       "      <td>-0.099749</td>\n",
       "      <td>-0.339577</td>\n",
       "      <td>-0.100445</td>\n",
       "      <td>-0.339328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>26</td>\n",
       "      <td>2.048286</td>\n",
       "      <td>0.077550</td>\n",
       "      <td>0.628814</td>\n",
       "      <td>-0.449189</td>\n",
       "      <td>1.485955</td>\n",
       "      <td>-0.150858</td>\n",
       "      <td>3.263714</td>\n",
       "      <td>-0.084589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082108</td>\n",
       "      <td>0.241587</td>\n",
       "      <td>-0.013242</td>\n",
       "      <td>-0.036473</td>\n",
       "      <td>0.042146</td>\n",
       "      <td>0.190616</td>\n",
       "      <td>-0.021206</td>\n",
       "      <td>-0.033463</td>\n",
       "      <td>0.078543</td>\n",
       "      <td>0.306113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fn_video  frame_number  distance_face130_r_hand8  \\\n",
       "21  csf001.mp4            22                  4.544161   \n",
       "22  csf001.mp4            23                  4.432777   \n",
       "23  csf001.mp4            24                  4.395037   \n",
       "24  csf001.mp4            25                  2.349447   \n",
       "25  csf001.mp4            26                  2.048286   \n",
       "\n",
       "    tan_angle_face130_r_hand8  distance_face152_r_hand8  \\\n",
       "21                   0.215778                  2.993590   \n",
       "22                   0.226310                  2.886811   \n",
       "23                   0.227604                  2.859063   \n",
       "24                   0.122057                  0.855116   \n",
       "25                   0.077550                  0.628814   \n",
       "\n",
       "    tan_angle_face152_r_hand8  distance_face94_r_hand8  \\\n",
       "21                   0.198311                 3.952022   \n",
       "22                   0.213178                 3.815771   \n",
       "23                   0.215205                 3.769736   \n",
       "24                  -0.115871                 1.760024   \n",
       "25                  -0.449189                 1.485955   \n",
       "\n",
       "    tan_angle_face94_r_hand8  distance_face130_r_hand9  \\\n",
       "21                  0.148803                  5.012093   \n",
       "22                  0.157548                  5.075631   \n",
       "23                  0.158046                  5.071182   \n",
       "24                 -0.052596                  3.514490   \n",
       "25                 -0.150858                  3.263714   \n",
       "\n",
       "    tan_angle_face130_r_hand9  ...  acceleration_x_r_hand8  \\\n",
       "21                   0.068935  ...                     NaN   \n",
       "22                   0.046591  ...                     NaN   \n",
       "23                   0.037993  ...               -0.003090   \n",
       "24                  -0.052680  ...               -0.099307   \n",
       "25                  -0.084589  ...                0.082108   \n",
       "\n",
       "    acceleration_y_r_hand8  velocity_x_r_hand9  velocity_y_r_hand9  \\\n",
       "21                     NaN                 NaN                 NaN   \n",
       "22                     NaN           -0.016066            0.009251   \n",
       "23                0.012441           -0.006354           -0.001570   \n",
       "24               -0.273851           -0.055388           -0.227089   \n",
       "25                0.241587           -0.013242           -0.036473   \n",
       "\n",
       "    acceleration_x_r_hand9  acceleration_y_r_hand9  velocity_x_r_hand12  \\\n",
       "21                     NaN                     NaN                  NaN   \n",
       "22                     NaN                     NaN             0.009077   \n",
       "23                0.009712               -0.010821             0.000696   \n",
       "24               -0.049035               -0.225518            -0.099749   \n",
       "25                0.042146                0.190616            -0.021206   \n",
       "\n",
       "    velocity_y_r_hand12  acceleration_x_r_hand12  acceleration_y_r_hand12  \n",
       "21                  NaN                      NaN                      NaN  \n",
       "22            -0.019512                      NaN                      NaN  \n",
       "23            -0.000249                -0.008381                 0.019263  \n",
       "24            -0.339577                -0.100445                -0.339328  \n",
       "25            -0.033463                 0.078543                 0.306113  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\bouba\\OneDrive\\Documents\\ACSR\\ACSR\\output\\extracted_features_mp4\\csf001_features.csv\")\n",
    "df.dropna(how='all', inplace=True, subset=df.columns[-25:])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(features_path, annotations_path):\n",
    "    # Load the feature file\n",
    "    features_df = pd.read_csv(features_path)\n",
    "    \n",
    "    # Load the annotation file\n",
    "    # Use header=0 to indicate that the first row is the header\n",
    "    annotations_df = pd.read_csv(annotations_path, header=0, names=['frame', 'shape', 'position'])\n",
    "    \n",
    "    # Convert the 'frame' column to integers\n",
    "    annotations_df['frame'] = pd.to_numeric(annotations_df['frame'], errors='coerce')\n",
    "    \n",
    "    # Drop rows with invalid frame numbers (e.g., NaN after conversion)\n",
    "    # annotations_df.dropna(subset=['frame'], inplace=True)\n",
    "    # annotations_df['frame'] = annotations_df['frame'].astype(int)\n",
    "    \n",
    "    # Strip whitespace from 'shape' and 'position' columns\n",
    "    annotations_df['shape'] = annotations_df['shape'].astype(str).str.strip()\n",
    "    annotations_df['position'] = annotations_df['position'].astype(str).str.strip()\n",
    "    \n",
    "    # Replace '_' with NaN in the 'shape' and 'position' columns\n",
    "    annotations_df['shape'] = annotations_df['shape'].replace('_', np.nan)\n",
    "    annotations_df['position'] = annotations_df['position'].replace('_', np.nan)\n",
    "    \n",
    "    # Find the first and last non-empty frame in the features DataFrame\n",
    "    # Drop rows where all feature columns are NaN\n",
    "    non_empty_features_df = features_df.dropna(how='all', subset=features_df.columns[2:])\n",
    "    first_non_empty_frame = non_empty_features_df['frame_number'].min()\n",
    "    last_non_empty_frame = non_empty_features_df['frame_number'].max()\n",
    "    \n",
    "    # Adjust the first and last frame in the annotations to match the first and last non-empty frame in the features\n",
    "    if annotations_df.iloc[0]['frame'] != first_non_empty_frame:\n",
    "        print(f\"Adjusting first annotation frame from {annotations_df.iloc[0]['frame']} to {first_non_empty_frame}\")\n",
    "        annotations_df.iloc[0, annotations_df.columns.get_loc('frame')] = first_non_empty_frame\n",
    "    if annotations_df.iloc[-1]['frame'] != last_non_empty_frame:\n",
    "        print(f\"Adjusting last annotation frame from {annotations_df.iloc[-1]['frame']} to {last_non_empty_frame}\")\n",
    "        annotations_df.iloc[-1, annotations_df.columns.get_loc('frame')] = last_non_empty_frame\n",
    "    \n",
    "    # Add shape and position columns to the features DataFrame\n",
    "    # Explicitly cast to object (string) type to avoid dtype warnings\n",
    "    features_df['shape'] = None\n",
    "    features_df['shape'] = features_df['shape'].astype(object)\n",
    "    features_df['position'] = None\n",
    "    features_df['position'] = features_df['position'].astype(object)\n",
    "    \n",
    "    # Set shape and position to NaN for frames before the first annotation frame\n",
    "    first_annotation_frame = annotations_df.iloc[0]['frame']\n",
    "    features_df.loc[features_df['frame_number'] < first_annotation_frame, 'shape'] = np.nan\n",
    "    features_df.loc[features_df['frame_number'] < first_annotation_frame, 'position'] = np.nan\n",
    "    \n",
    "    # Iterate through the annotation rows and fill in the shape and position\n",
    "    for i in range(len(annotations_df) - 1):\n",
    "        start_frame = annotations_df.iloc[i]['frame']\n",
    "        end_frame = annotations_df.iloc[i + 1]['frame']\n",
    "        shape = annotations_df.iloc[i]['shape']\n",
    "        position = annotations_df.iloc[i]['position']\n",
    "        \n",
    "        # Print the values being assigned for debugging\n",
    "        print(f\"Assigning shape={shape}, position={position} for frames {start_frame} to {end_frame - 1}\")\n",
    "        \n",
    "        # Fill in the shape and position for the range of frames\n",
    "        features_df.loc[(features_df['frame_number'] >= start_frame) & \n",
    "                        (features_df['frame_number'] < end_frame), 'shape'] = shape\n",
    "        features_df.loc[(features_df['frame_number'] >= start_frame) & \n",
    "                        (features_df['frame_number'] < end_frame), 'position'] = position\n",
    "    \n",
    "    # Handle the last row of annotations\n",
    "    last_annotation_frame = annotations_df.iloc[-1]['frame']\n",
    "    shape = annotations_df.iloc[-1]['shape']\n",
    "    position = annotations_df.iloc[-1]['position']\n",
    "    \n",
    "    # Print the values being assigned for debugging\n",
    "    print(f\"Assigning shape={shape}, position={position} for frames {last_annotation_frame} to end\")\n",
    "    \n",
    "    # Fill in the shape and position for the last range\n",
    "    features_df.loc[features_df['frame_number'] >= last_annotation_frame, 'shape'] = shape\n",
    "    features_df.loc[features_df['frame_number'] >= last_annotation_frame, 'position'] = position\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting first annotation frame from 25 to 22\n",
      "Adjusting last annotation frame from 133 to 131\n",
      "Assigning shape=5, position=1 for frames 22 to 33\n",
      "Assigning shape=6, position=1 for frames 34 to 40\n",
      "Assigning shape=6, position=2 for frames 41 to 46\n",
      "Assigning shape=5, position=3 for frames 47 to 54\n",
      "Assigning shape=0, position=0 for frames 55 to 56\n",
      "Assigning shape=2, position=1 for frames 57 to 65\n",
      "Assigning shape=2, position=4 for frames 66 to 74\n",
      "Assigning shape=3, position=4 for frames 75 to 85\n",
      "Assigning shape=3, position=3 for frames 86 to 123\n",
      "Assigning shape=3, position=0 for frames 124 to 126\n",
      "Assigning shape=0, position=0 for frames 127 to 130\n",
      "Assigning shape=nan, position=nan for frames 131 to end\n",
      "Adjusting first annotation frame from 29 to 27\n",
      "Adjusting last annotation frame from 373 to 372\n",
      "Assigning shape=5, position=0 for frames 27 to 35\n",
      "Assigning shape=5, position=3 for frames 36 to 45\n",
      "Assigning shape=6, position=1 for frames 46 to 53\n",
      "Assigning shape=0, position=0 for frames 54 to 61\n",
      "Assigning shape=3, position=2 for frames 62 to 75\n",
      "Assigning shape=0, position=0 for frames 76 to 76\n",
      "Assigning shape=7, position=1 for frames 77 to 86\n",
      "Assigning shape=0, position=0 for frames 87 to 91\n",
      "Assigning shape=3, position=0 for frames 92 to 93\n",
      "Assigning shape=3, position=2 for frames 94 to 95\n",
      "Assigning shape=3, position=3 for frames 96 to 104\n",
      "Assigning shape=5, position=3 for frames 105 to 119\n",
      "Assigning shape=3, position=3 for frames 120 to 130\n",
      "Assigning shape=3, position=2 for frames 131 to 141\n",
      "Assigning shape=0, position=0 for frames 142 to 142\n",
      "Assigning shape=0, position=0 for frames 143 to 143\n",
      "Assigning shape=1, position=2 for frames 144 to 147\n",
      "Assigning shape=1, position=5 for frames 148 to 162\n",
      "Assigning shape=0, position=5 for frames 163 to 168\n",
      "Assigning shape=3, position=4 for frames 169 to 170\n",
      "Assigning shape=3, position=0 for frames 171 to 173\n",
      "Assigning shape=3, position=3 for frames 174 to 178\n",
      "Assigning shape=1, position=1 for frames 179 to 184\n",
      "Assigning shape=6, position=1 for frames 185 to 202\n",
      "Assigning shape=5, position=1 for frames 203 to 210\n",
      "Assigning shape=0, position=0 for frames 211 to 214\n",
      "Assigning shape=2, position=0 for frames 215 to 217\n",
      "Assigning shape=2, position=4 for frames 218 to 228\n",
      "Assigning shape=2, position=0 for frames 229 to 234\n",
      "Assigning shape=3, position=0 for frames 235 to 236\n",
      "Assigning shape=3, position=2 for frames 237 to 257\n",
      "Assigning shape=4, position=2 for frames 258 to 263\n",
      "Assigning shape=4, position=3 for frames 264 to 275\n",
      "Assigning shape=0, position=0 for frames 276 to 279\n",
      "Assigning shape=2, position=1 for frames 280 to 291\n",
      "Assigning shape=1, position=1 for frames 292 to 293\n",
      "Assigning shape=1, position=5 for frames 294 to 306\n",
      "Assigning shape=6, position=0 for frames 307 to 312\n",
      "Assigning shape=6, position=3 for frames 313 to 360\n",
      "Assigning shape=6, position=0 for frames 361 to 366\n",
      "Assigning shape=0, position=0 for frames 367 to 371\n",
      "Assigning shape=nan, position=nan for frames 372 to end\n",
      "Adjusting first annotation frame from 36 to 34\n",
      "Adjusting last annotation frame from 179 to 176\n",
      "Assigning shape=2, position=0 for frames 34 to 41\n",
      "Assigning shape=2, position=1 for frames 42 to 51\n",
      "Assigning shape=6, position=1 for frames 52 to 72\n",
      "Assigning shape=6, position=0 for frames 73 to 74\n",
      "Assigning shape=6, position=5 for frames 75 to 90\n",
      "Assigning shape=4, position=4 for frames 91 to 107\n",
      "Assigning shape=0, position=4 for frames 108 to 113\n",
      "Assigning shape=1, position=0 for frames 114 to 115\n",
      "Assigning shape=1, position=3 for frames 116 to 167\n",
      "Assigning shape=1, position=0 for frames 168 to 172\n",
      "Assigning shape=1, position=0 for frames 173 to 175\n",
      "Assigning shape=0, position=0 for frames 176 to 175\n",
      "Assigning shape=nan, position=nan for frames 176 to end\n",
      "Adjusting first annotation frame from 36 to 39\n",
      "Adjusting last annotation frame from 179 to 335\n",
      "Assigning shape=2, position=0 for frames 39 to 41\n",
      "Assigning shape=2, position=1 for frames 42 to 51\n",
      "Assigning shape=6, position=1 for frames 52 to 72\n",
      "Assigning shape=6, position=0 for frames 73 to 74\n",
      "Assigning shape=6, position=5 for frames 75 to 90\n",
      "Assigning shape=4, position=4 for frames 91 to 107\n",
      "Assigning shape=0, position=4 for frames 108 to 113\n",
      "Assigning shape=1, position=0 for frames 114 to 115\n",
      "Assigning shape=1, position=3 for frames 116 to 167\n",
      "Assigning shape=1, position=0 for frames 168 to 172\n",
      "Assigning shape=1, position=0 for frames 173 to 175\n",
      "Assigning shape=0, position=0 for frames 176 to 334\n",
      "Assigning shape=nan, position=nan for frames 335 to end\n",
      "Adjusting first annotation frame from 44 to 46\n",
      "Adjusting last annotation frame from 180 to 177\n",
      "Assigning shape=0, position=0 for frames 46 to 46\n",
      "Assigning shape=1, position=0 for frames 47 to 56\n",
      "Assigning shape=1, position=4 for frames 57 to 67\n",
      "Assigning shape=4, position=5 for frames 68 to 81\n",
      "Assigning shape=1, position=0 for frames 82 to 85\n",
      "Assigning shape=1, position=2 for frames 86 to 101\n",
      "Assigning shape=5, position=3 for frames 102 to 116\n",
      "Assigning shape=2, position=0 for frames 117 to 123\n",
      "Assigning shape=2, position=4 for frames 124 to 167\n",
      "Assigning shape=2, position=5 for frames 168 to 170\n",
      "Assigning shape=0, position=0 for frames 171 to 176\n",
      "Assigning shape=nan, position=nan for frames 177 to end\n",
      "Adjusting first annotation frame from 41 to 40\n",
      "Adjusting last annotation frame from 352 to 349\n",
      "Assigning shape=0, position=0 for frames 40 to 42\n",
      "Assigning shape=6, position=0 for frames 43 to 47\n",
      "Assigning shape=6, position=5 for frames 48 to 61\n",
      "Assigning shape=6, position=0 for frames 62 to 66\n",
      "Assigning shape=1, position=0 for frames 67 to 70\n",
      "Assigning shape=1, position=2 for frames 71 to 85\n",
      "Assigning shape=2, position=0 for frames 86 to 86\n",
      "Assigning shape=2, position=1 for frames 87 to 96\n",
      "Assigning shape=4, position=1 for frames 97 to 100\n",
      "Assigning shape=5, position=1 for frames 101 to 104\n",
      "Assigning shape=8, position=1 for frames 105 to 111\n",
      "Assigning shape=8, position=3 for frames 112 to 126\n",
      "Assigning shape=0, position=0 for frames 127 to 131\n",
      "Assigning shape=3, position=2 for frames 132 to 149\n",
      "Assigning shape=3, position=3 for frames 150 to 160\n",
      "Assigning shape=3, position=0 for frames 161 to 163\n",
      "Assigning shape=5, position=1 for frames 164 to 175\n",
      "Assigning shape=0, position=1 for frames 176 to 177\n",
      "Assigning shape=3, position=1 for frames 178 to 187\n",
      "Assigning shape=5, position=1 for frames 188 to 192\n",
      "Assigning shape=5, position=5 for frames 193 to 209\n",
      "Assigning shape=5, position=0 for frames 210 to 212\n",
      "Assigning shape=1, position=0 for frames 213 to 217\n",
      "Assigning shape=1, position=2 for frames 218 to 236\n",
      "Assigning shape=0, position=0 for frames 237 to 237\n",
      "Assigning shape=5, position=1 for frames 238 to 255\n",
      "Assigning shape=3, position=1 for frames 256 to 341\n",
      "Assigning shape=0, position=0 for frames 342 to 348\n",
      "Assigning shape=nan, position=nan for frames 349 to end\n",
      "Adjusting first annotation frame from 46 to 43\n",
      "Adjusting last annotation frame from 214 to 213\n",
      "Assigning shape=5, position=0 for frames 43 to 54\n",
      "Assigning shape=5, position=4 for frames 55 to 59\n",
      "Assigning shape=0, position=0 for frames 60 to 64\n",
      "Assigning shape=8, position=0 for frames 65 to 71\n",
      "Assigning shape=8, position=2 for frames 72 to 85\n",
      "Assigning shape=0, position=0 for frames 86 to 88\n",
      "Assigning shape=5, position=1 for frames 89 to 99\n",
      "Assigning shape=6, position=1 for frames 100 to 119\n",
      "Assigning shape=5, position=1 for frames 120 to 129\n",
      "Assigning shape=3, position=1 for frames 130 to 133\n",
      "Assigning shape=3, position=0 for frames 134 to 137\n",
      "Assigning shape=3, position=3 for frames 138 to 196\n",
      "Assigning shape=3, position=4 for frames 197 to 200\n",
      "Assigning shape=3, position=5 for frames 201 to 204\n",
      "Assigning shape=0, position=0 for frames 205 to 212\n",
      "Assigning shape=nan, position=nan for frames 213 to end\n",
      "Adjusting first annotation frame from 38 to 36\n",
      "Adjusting last annotation frame from 323 to 325\n",
      "Assigning shape=5, position=0 for frames 36 to 49\n",
      "Assigning shape=5, position=1 for frames 50 to 63\n",
      "Assigning shape=4, position=1 for frames 64 to 64\n",
      "Assigning shape=4, position=0 for frames 65 to 71\n",
      "Assigning shape=3, position=nan for frames 72 to 83\n",
      "Assigning shape=0, position=3 for frames 84 to 84\n",
      "Assigning shape=3, position=3 for frames 85 to 104\n",
      "Assigning shape=4, position=0 for frames 105 to 121\n",
      "Assigning shape=4, position=3 for frames 122 to 144\n",
      "Assigning shape=6, position=1 for frames 145 to 157\n",
      "Assigning shape=6, position=0 for frames 158 to 161\n",
      "Assigning shape=6, position=2 for frames 162 to 174\n",
      "Assigning shape=1, position=1 for frames 175 to 176\n",
      "Assigning shape=1, position=0 for frames 177 to 187\n",
      "Assigning shape=1, position=2 for frames 188 to 197\n",
      "Assigning shape=0, position=0 for frames 198 to 203\n",
      "Assigning shape=5, position=5 for frames 204 to 220\n",
      "Assigning shape=0, position=0 for frames 221 to 224\n",
      "Assigning shape=1, position=1 for frames 225 to 233\n",
      "Assigning shape=0, position=0 for frames 234 to 237\n",
      "Assigning shape=3, position=3 for frames 238 to 308\n",
      "Assigning shape=3, position=0 for frames 309 to 311\n",
      "Assigning shape=0, position=0 for frames 312 to 324\n",
      "Assigning shape=nan, position=nan for frames 325 to end\n",
      "Adjusting first annotation frame from 40 to 38\n",
      "Adjusting last annotation frame from 160 to 163\n",
      "Assigning shape=5, position=0 for frames 38 to 47\n",
      "Assigning shape=5, position=3 for frames 48 to 65\n",
      "Assigning shape=0, position=0 for frames 66 to 67\n",
      "Assigning shape=6, position=1 for frames 68 to 77\n",
      "Assigning shape=1, position=1 for frames 78 to 80\n",
      "Assigning shape=1, position=0 for frames 81 to 83\n",
      "Assigning shape=1, position=5 for frames 84 to 94\n",
      "Assigning shape=0, position=0 for frames 95 to 98\n",
      "Assigning shape=7, position=0 for frames 99 to 101\n",
      "Assigning shape=7, position=3 for frames 102 to 148\n",
      "Assigning shape=7, position=0 for frames 149 to 152\n",
      "Assigning shape=0, position=0 for frames 153 to 162\n",
      "Assigning shape=nan, position=nan for frames 163 to end\n",
      "Adjusting first annotation frame from 40 to 37\n",
      "Adjusting last annotation frame from 343 to 344\n",
      "Assigning shape=0, position=0 for frames 37 to 40\n",
      "Assigning shape=6, position=0 for frames 41 to 45\n",
      "Assigning shape=6, position=1 for frames 46 to 53\n",
      "Assigning shape=0, position=1 for frames 54 to 55\n",
      "Assigning shape=2, position=1 for frames 56 to 59\n",
      "Assigning shape=2, position=0 for frames 60 to 63\n",
      "Assigning shape=2, position=4 for frames 64 to 73\n",
      "Assigning shape=0, position=4 for frames 74 to 78\n",
      "Assigning shape=3, position=4 for frames 79 to 90\n",
      "Assigning shape=0, position=0 for frames 91 to 92\n",
      "Assigning shape=6, position=1 for frames 93 to 104\n",
      "Assigning shape=1, position=1 for frames 105 to 115\n",
      "Assigning shape=0, position=1 for frames 116 to 119\n",
      "Assigning shape=0, position=0 for frames 120 to 121\n",
      "Assigning shape=3, position=0 for frames 122 to 131\n",
      "Assigning shape=3, position=4 for frames 132 to 135\n",
      "Assigning shape=0, position=4 for frames 136 to 140\n",
      "Assigning shape=0, position=0 for frames 141 to 147\n",
      "Assigning shape=3, position=1 for frames 148 to 176\n",
      "Assigning shape=5, position=4 for frames 177 to 194\n",
      "Assigning shape=5, position=0 for frames 195 to 198\n",
      "Assigning shape=5, position=3 for frames 199 to 209\n",
      "Assigning shape=0, position=0 for frames 210 to 214\n",
      "Assigning shape=2, position=0 for frames 215 to 217\n",
      "Assigning shape=2, position=1 for frames 218 to 225\n",
      "Assigning shape=0, position=0 for frames 226 to 228\n",
      "Assigning shape=3, position=0 for frames 229 to 231\n",
      "Assigning shape=3, position=5 for frames 232 to 253\n",
      "Assigning shape=0, position=0 for frames 254 to 255\n",
      "Assigning shape=6, position=0 for frames 256 to 258\n",
      "Assigning shape=6, position=5 for frames 259 to 270\n",
      "Assigning shape=2, position=5 for frames 271 to 275\n",
      "Assigning shape=2, position=0 for frames 276 to 278\n",
      "Assigning shape=8, position=0 for frames 279 to 285\n",
      "Assigning shape=8, position=5 for frames 286 to 339\n",
      "Assigning shape=2, position=0 for frames 340 to 341\n",
      "Assigning shape=0, position=0 for frames 342 to 343\n",
      "Assigning shape=nan, position=nan for frames 344 to end\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store processed DataFrames\n",
    "processed_dfs = []\n",
    "\n",
    "# Iterate through all feature files\n",
    "for feature_file in os.listdir(features_dir):\n",
    "    if feature_file.endswith('.csv'):\n",
    "        # Construct the full path to the feature file\n",
    "        features_path = os.path.join(features_dir, feature_file)\n",
    "        \n",
    "        # Construct the corresponding annotation file path\n",
    "        annotation_file = feature_file.replace('_features.csv', '_annotations.csv')\n",
    "        annotations_path = os.path.join(annotations_dir, annotation_file)\n",
    "        \n",
    "        # Check if the annotation file exists\n",
    "        if os.path.exists(annotations_path):\n",
    "            # Process the files\n",
    "            processed_df = process_files(features_path, annotations_path)\n",
    "            processed_dfs.append(processed_df)\n",
    "        else:\n",
    "            print(f\"Annotation file not found for {feature_file}\")\n",
    "\n",
    "# Concatenate all processed DataFrames\n",
    "training_df = pd.concat(processed_dfs[:-1], ignore_index=True)\n",
    "testing_df = processed_dfs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn_video</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>distance_face130_r_hand8</th>\n",
       "      <th>tan_angle_face130_r_hand8</th>\n",
       "      <th>distance_face152_r_hand8</th>\n",
       "      <th>tan_angle_face152_r_hand8</th>\n",
       "      <th>distance_face94_r_hand8</th>\n",
       "      <th>tan_angle_face94_r_hand8</th>\n",
       "      <th>distance_face130_r_hand9</th>\n",
       "      <th>tan_angle_face130_r_hand9</th>\n",
       "      <th>...</th>\n",
       "      <th>distance_r_hand9_r_hand12</th>\n",
       "      <th>distance_r_hand13_r_hand16</th>\n",
       "      <th>distance_r_hand17_r_hand20</th>\n",
       "      <th>distance_r_hand4_r_hand5</th>\n",
       "      <th>distance_r_hand4_r_hand8</th>\n",
       "      <th>distance_r_hand8_r_hand12</th>\n",
       "      <th>distance_r_hand7_r_hand11</th>\n",
       "      <th>distance_r_hand6_r_hand10</th>\n",
       "      <th>shape</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>csf009.mp4</td>\n",
       "      <td>587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>csf009.mp4</td>\n",
       "      <td>588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5132</th>\n",
       "      <td>csf009.mp4</td>\n",
       "      <td>589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5133</th>\n",
       "      <td>csf009.mp4</td>\n",
       "      <td>590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5134</th>\n",
       "      <td>csf009.mp4</td>\n",
       "      <td>591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5135 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fn_video  frame_number  distance_face130_r_hand8  \\\n",
       "0     csf001.mp4             1                       NaN   \n",
       "1     csf001.mp4             2                       NaN   \n",
       "2     csf001.mp4             3                       NaN   \n",
       "3     csf001.mp4             4                       NaN   \n",
       "4     csf001.mp4             5                       NaN   \n",
       "...          ...           ...                       ...   \n",
       "5130  csf009.mp4           587                       NaN   \n",
       "5131  csf009.mp4           588                       NaN   \n",
       "5132  csf009.mp4           589                       NaN   \n",
       "5133  csf009.mp4           590                       NaN   \n",
       "5134  csf009.mp4           591                       NaN   \n",
       "\n",
       "      tan_angle_face130_r_hand8  distance_face152_r_hand8  \\\n",
       "0                           NaN                       NaN   \n",
       "1                           NaN                       NaN   \n",
       "2                           NaN                       NaN   \n",
       "3                           NaN                       NaN   \n",
       "4                           NaN                       NaN   \n",
       "...                         ...                       ...   \n",
       "5130                        NaN                       NaN   \n",
       "5131                        NaN                       NaN   \n",
       "5132                        NaN                       NaN   \n",
       "5133                        NaN                       NaN   \n",
       "5134                        NaN                       NaN   \n",
       "\n",
       "      tan_angle_face152_r_hand8  distance_face94_r_hand8  \\\n",
       "0                           NaN                      NaN   \n",
       "1                           NaN                      NaN   \n",
       "2                           NaN                      NaN   \n",
       "3                           NaN                      NaN   \n",
       "4                           NaN                      NaN   \n",
       "...                         ...                      ...   \n",
       "5130                        NaN                      NaN   \n",
       "5131                        NaN                      NaN   \n",
       "5132                        NaN                      NaN   \n",
       "5133                        NaN                      NaN   \n",
       "5134                        NaN                      NaN   \n",
       "\n",
       "      tan_angle_face94_r_hand8  distance_face130_r_hand9  \\\n",
       "0                          NaN                       NaN   \n",
       "1                          NaN                       NaN   \n",
       "2                          NaN                       NaN   \n",
       "3                          NaN                       NaN   \n",
       "4                          NaN                       NaN   \n",
       "...                        ...                       ...   \n",
       "5130                       NaN                       NaN   \n",
       "5131                       NaN                       NaN   \n",
       "5132                       NaN                       NaN   \n",
       "5133                       NaN                       NaN   \n",
       "5134                       NaN                       NaN   \n",
       "\n",
       "      tan_angle_face130_r_hand9  ...  distance_r_hand9_r_hand12  \\\n",
       "0                           NaN  ...                        NaN   \n",
       "1                           NaN  ...                        NaN   \n",
       "2                           NaN  ...                        NaN   \n",
       "3                           NaN  ...                        NaN   \n",
       "4                           NaN  ...                        NaN   \n",
       "...                         ...  ...                        ...   \n",
       "5130                        NaN  ...                        NaN   \n",
       "5131                        NaN  ...                        NaN   \n",
       "5132                        NaN  ...                        NaN   \n",
       "5133                        NaN  ...                        NaN   \n",
       "5134                        NaN  ...                        NaN   \n",
       "\n",
       "      distance_r_hand13_r_hand16  distance_r_hand17_r_hand20  \\\n",
       "0                            NaN                         NaN   \n",
       "1                            NaN                         NaN   \n",
       "2                            NaN                         NaN   \n",
       "3                            NaN                         NaN   \n",
       "4                            NaN                         NaN   \n",
       "...                          ...                         ...   \n",
       "5130                         NaN                         NaN   \n",
       "5131                         NaN                         NaN   \n",
       "5132                         NaN                         NaN   \n",
       "5133                         NaN                         NaN   \n",
       "5134                         NaN                         NaN   \n",
       "\n",
       "      distance_r_hand4_r_hand5  distance_r_hand4_r_hand8  \\\n",
       "0                          NaN                       NaN   \n",
       "1                          NaN                       NaN   \n",
       "2                          NaN                       NaN   \n",
       "3                          NaN                       NaN   \n",
       "4                          NaN                       NaN   \n",
       "...                        ...                       ...   \n",
       "5130                       NaN                       NaN   \n",
       "5131                       NaN                       NaN   \n",
       "5132                       NaN                       NaN   \n",
       "5133                       NaN                       NaN   \n",
       "5134                       NaN                       NaN   \n",
       "\n",
       "      distance_r_hand8_r_hand12  distance_r_hand7_r_hand11  \\\n",
       "0                           NaN                        NaN   \n",
       "1                           NaN                        NaN   \n",
       "2                           NaN                        NaN   \n",
       "3                           NaN                        NaN   \n",
       "4                           NaN                        NaN   \n",
       "...                         ...                        ...   \n",
       "5130                        NaN                        NaN   \n",
       "5131                        NaN                        NaN   \n",
       "5132                        NaN                        NaN   \n",
       "5133                        NaN                        NaN   \n",
       "5134                        NaN                        NaN   \n",
       "\n",
       "      distance_r_hand6_r_hand10  shape  position  \n",
       "0                           NaN    NaN       NaN  \n",
       "1                           NaN    NaN       NaN  \n",
       "2                           NaN    NaN       NaN  \n",
       "3                           NaN    NaN       NaN  \n",
       "4                           NaN    NaN       NaN  \n",
       "...                         ...    ...       ...  \n",
       "5130                        NaN    NaN       NaN  \n",
       "5131                        NaN    NaN       NaN  \n",
       "5132                        NaN    NaN       NaN  \n",
       "5133                        NaN    NaN       NaN  \n",
       "5134                        NaN    NaN       NaN  \n",
       "\n",
       "[5135 rows x 32 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn_video</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>distance_face130_r_hand8</th>\n",
       "      <th>tan_angle_face130_r_hand8</th>\n",
       "      <th>distance_face152_r_hand8</th>\n",
       "      <th>tan_angle_face152_r_hand8</th>\n",
       "      <th>distance_face94_r_hand8</th>\n",
       "      <th>tan_angle_face94_r_hand8</th>\n",
       "      <th>distance_face130_r_hand9</th>\n",
       "      <th>tan_angle_face130_r_hand9</th>\n",
       "      <th>...</th>\n",
       "      <th>distance_r_hand9_r_hand12</th>\n",
       "      <th>distance_r_hand13_r_hand16</th>\n",
       "      <th>distance_r_hand17_r_hand20</th>\n",
       "      <th>distance_r_hand4_r_hand5</th>\n",
       "      <th>distance_r_hand4_r_hand8</th>\n",
       "      <th>distance_r_hand8_r_hand12</th>\n",
       "      <th>distance_r_hand7_r_hand11</th>\n",
       "      <th>distance_r_hand6_r_hand10</th>\n",
       "      <th>shape</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>22</td>\n",
       "      <td>4.544161</td>\n",
       "      <td>0.215778</td>\n",
       "      <td>2.993590</td>\n",
       "      <td>0.198311</td>\n",
       "      <td>3.952022</td>\n",
       "      <td>0.148803</td>\n",
       "      <td>5.012093</td>\n",
       "      <td>0.068935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782956</td>\n",
       "      <td>0.718158</td>\n",
       "      <td>0.662323</td>\n",
       "      <td>1.021032</td>\n",
       "      <td>1.230642</td>\n",
       "      <td>0.300192</td>\n",
       "      <td>0.307430</td>\n",
       "      <td>0.312447</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>23</td>\n",
       "      <td>4.432777</td>\n",
       "      <td>0.226310</td>\n",
       "      <td>2.886811</td>\n",
       "      <td>0.213178</td>\n",
       "      <td>3.815771</td>\n",
       "      <td>0.157548</td>\n",
       "      <td>5.075631</td>\n",
       "      <td>0.046591</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034008</td>\n",
       "      <td>0.970525</td>\n",
       "      <td>0.768541</td>\n",
       "      <td>1.131261</td>\n",
       "      <td>1.215159</td>\n",
       "      <td>0.344842</td>\n",
       "      <td>0.344208</td>\n",
       "      <td>0.350192</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>24</td>\n",
       "      <td>4.395037</td>\n",
       "      <td>0.227604</td>\n",
       "      <td>2.859063</td>\n",
       "      <td>0.215205</td>\n",
       "      <td>3.769736</td>\n",
       "      <td>0.158046</td>\n",
       "      <td>5.071182</td>\n",
       "      <td>0.037993</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082609</td>\n",
       "      <td>1.007142</td>\n",
       "      <td>0.791769</td>\n",
       "      <td>1.152348</td>\n",
       "      <td>1.199444</td>\n",
       "      <td>0.403542</td>\n",
       "      <td>0.385788</td>\n",
       "      <td>0.371529</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>25</td>\n",
       "      <td>2.349447</td>\n",
       "      <td>0.122057</td>\n",
       "      <td>0.855116</td>\n",
       "      <td>-0.115871</td>\n",
       "      <td>1.760024</td>\n",
       "      <td>-0.052596</td>\n",
       "      <td>3.514490</td>\n",
       "      <td>-0.052680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.402755</td>\n",
       "      <td>1.344645</td>\n",
       "      <td>1.085438</td>\n",
       "      <td>0.907616</td>\n",
       "      <td>0.968761</td>\n",
       "      <td>0.188044</td>\n",
       "      <td>0.182620</td>\n",
       "      <td>0.222828</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>csf001.mp4</td>\n",
       "      <td>26</td>\n",
       "      <td>2.048286</td>\n",
       "      <td>0.077550</td>\n",
       "      <td>0.628814</td>\n",
       "      <td>-0.449189</td>\n",
       "      <td>1.485955</td>\n",
       "      <td>-0.150858</td>\n",
       "      <td>3.263714</td>\n",
       "      <td>-0.084589</td>\n",
       "      <td>...</td>\n",
       "      <td>1.357651</td>\n",
       "      <td>1.322012</td>\n",
       "      <td>1.091909</td>\n",
       "      <td>0.831381</td>\n",
       "      <td>0.986141</td>\n",
       "      <td>0.165219</td>\n",
       "      <td>0.176287</td>\n",
       "      <td>0.206447</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4701</th>\n",
       "      <td>csf009.mp4</td>\n",
       "      <td>158</td>\n",
       "      <td>3.633401</td>\n",
       "      <td>0.047730</td>\n",
       "      <td>2.190881</td>\n",
       "      <td>-0.088130</td>\n",
       "      <td>3.119843</td>\n",
       "      <td>-0.063451</td>\n",
       "      <td>4.025334</td>\n",
       "      <td>0.095946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163347</td>\n",
       "      <td>0.202792</td>\n",
       "      <td>0.234873</td>\n",
       "      <td>0.550827</td>\n",
       "      <td>0.491848</td>\n",
       "      <td>0.291843</td>\n",
       "      <td>0.306661</td>\n",
       "      <td>0.341848</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>csf009.mp4</td>\n",
       "      <td>159</td>\n",
       "      <td>3.607583</td>\n",
       "      <td>0.048617</td>\n",
       "      <td>2.163136</td>\n",
       "      <td>-0.088306</td>\n",
       "      <td>3.093030</td>\n",
       "      <td>-0.063503</td>\n",
       "      <td>4.044707</td>\n",
       "      <td>0.094881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180949</td>\n",
       "      <td>0.205921</td>\n",
       "      <td>0.220094</td>\n",
       "      <td>0.587791</td>\n",
       "      <td>0.473974</td>\n",
       "      <td>0.313544</td>\n",
       "      <td>0.319279</td>\n",
       "      <td>0.340213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>csf009.mp4</td>\n",
       "      <td>160</td>\n",
       "      <td>4.492134</td>\n",
       "      <td>0.089091</td>\n",
       "      <td>3.028027</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>3.956944</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>5.003909</td>\n",
       "      <td>0.097119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324217</td>\n",
       "      <td>0.312215</td>\n",
       "      <td>0.242825</td>\n",
       "      <td>0.658422</td>\n",
       "      <td>0.439765</td>\n",
       "      <td>0.217883</td>\n",
       "      <td>0.227596</td>\n",
       "      <td>0.258976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>csf009.mp4</td>\n",
       "      <td>161</td>\n",
       "      <td>4.499521</td>\n",
       "      <td>0.093242</td>\n",
       "      <td>3.039220</td>\n",
       "      <td>0.017124</td>\n",
       "      <td>3.973330</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>5.144874</td>\n",
       "      <td>0.106544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378522</td>\n",
       "      <td>0.347998</td>\n",
       "      <td>0.322012</td>\n",
       "      <td>0.674416</td>\n",
       "      <td>0.395973</td>\n",
       "      <td>0.292430</td>\n",
       "      <td>0.286585</td>\n",
       "      <td>0.313414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705</th>\n",
       "      <td>csf009.mp4</td>\n",
       "      <td>162</td>\n",
       "      <td>4.592378</td>\n",
       "      <td>0.088463</td>\n",
       "      <td>3.130195</td>\n",
       "      <td>0.012472</td>\n",
       "      <td>4.062007</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>5.156858</td>\n",
       "      <td>0.107930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294702</td>\n",
       "      <td>0.285276</td>\n",
       "      <td>0.261855</td>\n",
       "      <td>0.658989</td>\n",
       "      <td>0.456247</td>\n",
       "      <td>0.302042</td>\n",
       "      <td>0.297295</td>\n",
       "      <td>0.328603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1791 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fn_video  frame_number  distance_face130_r_hand8  \\\n",
       "21    csf001.mp4            22                  4.544161   \n",
       "22    csf001.mp4            23                  4.432777   \n",
       "23    csf001.mp4            24                  4.395037   \n",
       "24    csf001.mp4            25                  2.349447   \n",
       "25    csf001.mp4            26                  2.048286   \n",
       "...          ...           ...                       ...   \n",
       "4701  csf009.mp4           158                  3.633401   \n",
       "4702  csf009.mp4           159                  3.607583   \n",
       "4703  csf009.mp4           160                  4.492134   \n",
       "4704  csf009.mp4           161                  4.499521   \n",
       "4705  csf009.mp4           162                  4.592378   \n",
       "\n",
       "      tan_angle_face130_r_hand8  distance_face152_r_hand8  \\\n",
       "21                     0.215778                  2.993590   \n",
       "22                     0.226310                  2.886811   \n",
       "23                     0.227604                  2.859063   \n",
       "24                     0.122057                  0.855116   \n",
       "25                     0.077550                  0.628814   \n",
       "...                         ...                       ...   \n",
       "4701                   0.047730                  2.190881   \n",
       "4702                   0.048617                  2.163136   \n",
       "4703                   0.089091                  3.028027   \n",
       "4704                   0.093242                  3.039220   \n",
       "4705                   0.088463                  3.130195   \n",
       "\n",
       "      tan_angle_face152_r_hand8  distance_face94_r_hand8  \\\n",
       "21                     0.198311                 3.952022   \n",
       "22                     0.213178                 3.815771   \n",
       "23                     0.215205                 3.769736   \n",
       "24                    -0.115871                 1.760024   \n",
       "25                    -0.449189                 1.485955   \n",
       "...                         ...                      ...   \n",
       "4701                  -0.088130                 3.119843   \n",
       "4702                  -0.088306                 3.093030   \n",
       "4703                   0.010739                 3.956944   \n",
       "4704                   0.017124                 3.973330   \n",
       "4705                   0.012472                 4.062007   \n",
       "\n",
       "      tan_angle_face94_r_hand8  distance_face130_r_hand9  \\\n",
       "21                    0.148803                  5.012093   \n",
       "22                    0.157548                  5.075631   \n",
       "23                    0.158046                  5.071182   \n",
       "24                   -0.052596                  3.514490   \n",
       "25                   -0.150858                  3.263714   \n",
       "...                        ...                       ...   \n",
       "4701                 -0.063451                  4.025334   \n",
       "4702                 -0.063503                  4.044707   \n",
       "4703                  0.006773                  5.003909   \n",
       "4704                  0.011690                  5.144874   \n",
       "4705                  0.008150                  5.156858   \n",
       "\n",
       "      tan_angle_face130_r_hand9  ...  distance_r_hand9_r_hand12  \\\n",
       "21                     0.068935  ...                   0.782956   \n",
       "22                     0.046591  ...                   1.034008   \n",
       "23                     0.037993  ...                   1.082609   \n",
       "24                    -0.052680  ...                   1.402755   \n",
       "25                    -0.084589  ...                   1.357651   \n",
       "...                         ...  ...                        ...   \n",
       "4701                   0.095946  ...                   0.163347   \n",
       "4702                   0.094881  ...                   0.180949   \n",
       "4703                   0.097119  ...                   0.324217   \n",
       "4704                   0.106544  ...                   0.378522   \n",
       "4705                   0.107930  ...                   0.294702   \n",
       "\n",
       "      distance_r_hand13_r_hand16  distance_r_hand17_r_hand20  \\\n",
       "21                      0.718158                    0.662323   \n",
       "22                      0.970525                    0.768541   \n",
       "23                      1.007142                    0.791769   \n",
       "24                      1.344645                    1.085438   \n",
       "25                      1.322012                    1.091909   \n",
       "...                          ...                         ...   \n",
       "4701                    0.202792                    0.234873   \n",
       "4702                    0.205921                    0.220094   \n",
       "4703                    0.312215                    0.242825   \n",
       "4704                    0.347998                    0.322012   \n",
       "4705                    0.285276                    0.261855   \n",
       "\n",
       "      distance_r_hand4_r_hand5  distance_r_hand4_r_hand8  \\\n",
       "21                    1.021032                  1.230642   \n",
       "22                    1.131261                  1.215159   \n",
       "23                    1.152348                  1.199444   \n",
       "24                    0.907616                  0.968761   \n",
       "25                    0.831381                  0.986141   \n",
       "...                        ...                       ...   \n",
       "4701                  0.550827                  0.491848   \n",
       "4702                  0.587791                  0.473974   \n",
       "4703                  0.658422                  0.439765   \n",
       "4704                  0.674416                  0.395973   \n",
       "4705                  0.658989                  0.456247   \n",
       "\n",
       "      distance_r_hand8_r_hand12  distance_r_hand7_r_hand11  \\\n",
       "21                     0.300192                   0.307430   \n",
       "22                     0.344842                   0.344208   \n",
       "23                     0.403542                   0.385788   \n",
       "24                     0.188044                   0.182620   \n",
       "25                     0.165219                   0.176287   \n",
       "...                         ...                        ...   \n",
       "4701                   0.291843                   0.306661   \n",
       "4702                   0.313544                   0.319279   \n",
       "4703                   0.217883                   0.227596   \n",
       "4704                   0.292430                   0.286585   \n",
       "4705                   0.302042                   0.297295   \n",
       "\n",
       "      distance_r_hand6_r_hand10  shape  position  \n",
       "21                     0.312447      5         1  \n",
       "22                     0.350192      5         1  \n",
       "23                     0.371529      5         1  \n",
       "24                     0.222828      5         1  \n",
       "25                     0.206447      5         1  \n",
       "...                         ...    ...       ...  \n",
       "4701                   0.341848      0         0  \n",
       "4702                   0.340213      0         0  \n",
       "4703                   0.258976      0         0  \n",
       "4704                   0.313414      0         0  \n",
       "4705                   0.328603      0         0  \n",
       "\n",
       "[1791 rows x 32 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with missing values or nans\n",
    "#training_df.dropna(inplace=True, subset=training_df.columns[11:], how='all')\n",
    "#testing_df.dropna(inplace=True, subset=testing_df.columns[11:], how='all')\n",
    "training_df.dropna(inplace=True)\n",
    "testing_df.dropna(inplace=True)\n",
    "# Convert the 'shape' column to strings (or integers, if applicable)\n",
    "training_df['shape'] = training_df['shape'].astype(int)\n",
    "testing_df['shape'] = testing_df['shape'].astype(int)\n",
    "training_df['position'] = training_df['position'].astype(int)\n",
    "testing_df['position'] = testing_df['position'].astype(int)\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([278, 220, 140, 425, 114, 246, 261,  64,  43], dtype=int64))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(training_df['shape'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1432, 28)\n",
      "X_val shape: (359, 28)\n",
      "y_shape_train shape: (1432,)\n",
      "y_shape_val shape: (359,)\n",
      "y_position_train shape: (1432,)\n",
      "y_position_val shape: (359,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove rows with missing values or NaNs\n",
    "training_df.dropna(inplace=True)\n",
    "testing_df.dropna(inplace=True)\n",
    "\n",
    "# Prepare features and targets\n",
    "X_train = training_df.drop(columns=['fn_video', 'frame_number', 'shape', 'position'])\n",
    "y_shape = training_df['shape']\n",
    "y_position = training_df['position']\n",
    "\n",
    "X_test = testing_df.drop(columns=['fn_video', 'frame_number', 'shape', 'position'])\n",
    "y_shape_test = testing_df['shape']\n",
    "y_position_test = testing_df['position']\n",
    "\n",
    "# Perform train-validation split (only once)\n",
    "X_train, X_val, y_shape_train, y_shape_val, y_position_train, y_position_val = train_test_split(\n",
    "    X_train, y_shape, y_position, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_shape_train shape:\", y_shape_train.shape)\n",
    "print(\"y_shape_val shape:\", y_shape_val.shape)\n",
    "print(\"y_position_train shape:\", y_position_train.shape)\n",
    "print(\"y_position_val shape:\", y_position_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86        43\n",
      "           1       0.98      1.00      0.99        46\n",
      "           2       0.96      0.96      0.96        27\n",
      "           3       0.98      0.95      0.96        85\n",
      "           4       0.96      0.96      0.96        26\n",
      "           5       0.98      1.00      0.99        46\n",
      "           6       0.98      0.93      0.96        59\n",
      "           7       0.94      1.00      0.97        15\n",
      "           8       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.96       359\n",
      "   macro avg       0.96      0.97      0.96       359\n",
      "weighted avg       0.96      0.96      0.96       359\n",
      "\n",
      "Position Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        81\n",
      "           1       0.91      0.92      0.91        73\n",
      "           2       0.89      1.00      0.94        25\n",
      "           3       0.98      0.99      0.99       111\n",
      "           4       0.97      0.90      0.93        31\n",
      "           5       1.00      0.92      0.96        38\n",
      "\n",
      "    accuracy                           0.94       359\n",
      "   macro avg       0.94      0.94      0.94       359\n",
      "weighted avg       0.95      0.94      0.94       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train a model for shape\n",
    "shape_model = RandomForestClassifier(random_state=42)\n",
    "shape_model.fit(X_train, y_shape_train)\n",
    "\n",
    "# Evaluate the shape model\n",
    "y_shape_pred = shape_model.predict(X_val)\n",
    "print(\"Shape Model Classification Report:\")\n",
    "print(classification_report(y_shape_val, y_shape_pred))\n",
    "\n",
    "# Train a model for position\n",
    "position_model = RandomForestClassifier(random_state=42)\n",
    "position_model.fit(X_train, y_position_train)\n",
    "\n",
    "# Evaluate the position model\n",
    "y_position_pred = position_model.predict(X_val)\n",
    "print(\"Position Model Classification Report:\")\n",
    "print(classification_report(y_position_val, y_position_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86        52\n",
      "           1       0.94      0.94      0.94        72\n",
      "           2       0.93      0.90      0.92        30\n",
      "           3       0.97      0.93      0.95        75\n",
      "           4       0.78      0.96      0.86        26\n",
      "           5       1.00      0.98      0.99        55\n",
      "           6       0.90      0.96      0.93        49\n",
      "           7       1.00      1.00      1.00        18\n",
      "           8       1.00      0.75      0.86         8\n",
      "\n",
      "    accuracy                           0.93       385\n",
      "   macro avg       0.93      0.92      0.92       385\n",
      "weighted avg       0.94      0.93      0.93       385\n",
      "\n",
      "Position Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88       100\n",
      "           1       1.00      0.94      0.97        81\n",
      "           2       1.00      0.74      0.85        31\n",
      "           3       0.83      0.97      0.90       114\n",
      "           4       0.91      1.00      0.95        30\n",
      "           5       0.97      0.97      0.97        29\n",
      "\n",
      "    accuracy                           0.91       385\n",
      "   macro avg       0.94      0.91      0.92       385\n",
      "weighted avg       0.92      0.91      0.91       385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train a model for shape\n",
    "shape_model = RandomForestClassifier(random_state=42)\n",
    "shape_model.fit(X_train, y_shape_train)\n",
    "\n",
    "# Evaluate the shape model\n",
    "y_shape_pred = shape_model.predict(X_val)\n",
    "print(\"Shape Model Classification Report:\")\n",
    "print(classification_report(y_shape_val, y_shape_pred))\n",
    "\n",
    "# Train a model for position\n",
    "position_model = RandomForestClassifier(random_state=42)\n",
    "position_model.fit(X_train, y_position_train)\n",
    "\n",
    "# Evaluate the position model\n",
    "y_position_pred = position_model.predict(X_val)\n",
    "print(\"Position Model Classification Report:\")\n",
    "print(classification_report(y_position_val, y_position_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Model Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.53      0.39        43\n",
      "           1       0.06      0.55      0.11        11\n",
      "           2       0.88      0.59      0.71        39\n",
      "           3       0.82      0.46      0.59        80\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.84      0.94      0.89        33\n",
      "           6       0.67      0.35      0.46        40\n",
      "           8       0.00      0.00      0.00        61\n",
      "\n",
      "    accuracy                           0.44       307\n",
      "   macro avg       0.45      0.43      0.39       307\n",
      "weighted avg       0.55      0.44      0.46       307\n",
      "\n",
      "Position Model Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.65      0.39        71\n",
      "           1       0.81      0.44      0.57        78\n",
      "           3       0.34      1.00      0.51        11\n",
      "           4       0.85      0.54      0.66        54\n",
      "           5       0.84      0.33      0.48        93\n",
      "\n",
      "    accuracy                           0.49       307\n",
      "   macro avg       0.63      0.59      0.52       307\n",
      "weighted avg       0.69      0.49      0.51       307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict on the test set\n",
    "y_shape_pred = shape_model.predict(X_test)\n",
    "y_position_pred = position_model.predict(X_test)\n",
    "\n",
    "# Print classification reports with zero_division=0 (default behavior)\n",
    "print(\"Shape Model Test Classification Report:\")\n",
    "print(classification_report(y_shape_test, y_shape_pred, zero_division=0))\n",
    "\n",
    "print(\"Position Model Test Classification Report:\")\n",
    "print(classification_report(y_position_test, y_position_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Model Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.45      0.36        44\n",
      "           1       0.10      0.73      0.17        11\n",
      "           2       0.91      0.74      0.82        39\n",
      "           3       0.84      0.47      0.61        80\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.82      1.00      0.90        33\n",
      "           6       0.89      0.78      0.83        40\n",
      "           8       0.00      0.00      0.00        61\n",
      "\n",
      "    accuracy                           0.52       308\n",
      "   macro avg       0.48      0.52      0.46       308\n",
      "weighted avg       0.58      0.52      0.52       308\n",
      "\n",
      "Position Model Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.68      0.43        72\n",
      "           1       0.83      0.44      0.57        78\n",
      "           3       0.43      0.91      0.59        11\n",
      "           4       0.85      0.52      0.64        54\n",
      "           5       0.85      0.48      0.62        93\n",
      "\n",
      "    accuracy                           0.54       308\n",
      "   macro avg       0.65      0.61      0.57       308\n",
      "weighted avg       0.70      0.54      0.56       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict on the test set\n",
    "y_shape_pred = shape_model.predict(X_test)\n",
    "y_position_pred = position_model.predict(X_test)\n",
    "\n",
    "# Print classification reports with zero_division=0 (default behavior)\n",
    "print(\"Shape Model Test Classification Report:\")\n",
    "print(classification_report(y_shape_test, y_shape_pred, zero_division=0))\n",
    "\n",
    "print(\"Position Model Test Classification Report:\")\n",
    "print(classification_report(y_position_test, y_position_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun 24 11:37:05 2022\n",
    "\n",
    "\"\"\"\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import cv2  # Import opencv\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp  # Import mediapipe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textgrids\n",
    "from scipy.signal import argrelextrema, savgol_filter\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_model(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        model, feature_names = pickle.load(f)\n",
    "    return model, feature_names\n",
    "\n",
    "\n",
    "def load_video(path2file):\n",
    "    cap = cv2.VideoCapture(path2file)\n",
    "    cap.set(3,640) # camera width\n",
    "    cap.set(4,480) # camera height\n",
    "    return cap\n",
    "\n",
    "\n",
    "def extract_class_from_fn(fn):\n",
    "    '''\n",
    "    get class number from filename, e.g.,\n",
    "    '4' from 'position_04.mp4'\n",
    "    '''\n",
    "    if fn is not None:\n",
    "        st = fn.find('_') + 1\n",
    "        ed = fn.find('.')\n",
    "        c = fn[st:ed]#.split('_')[0]\n",
    "        return int(c)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_distance(df_name, landmark1, landmark2, norm_factor=None):\n",
    "    '''\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_name : TYPE\n",
    "        DESCRIPTION.\n",
    "    landmark1 : STR\n",
    "        name of first landmark (e.g., hand20)\n",
    "    landmark2 : STR\n",
    "        name of second landmark (e.g., face234)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    series for dataframe\n",
    "    The distance between landmark1 and landmark2\n",
    "\n",
    "    '''\n",
    "\n",
    "    x1 = df_name[f'x_{landmark1}']\n",
    "    x2 = df_name[f'x_{landmark2}']\n",
    "    y1 = df_name[f'y_{landmark1}']\n",
    "    y2 = df_name[f'y_{landmark2}']\n",
    "    z1 = df_name[f'z_{landmark1}']\n",
    "    z2 = df_name[f'z_{landmark2}']\n",
    "    d = np.sqrt((x1-x2)**2 + (y1-y2)**2 + (z1-z2)**2)\n",
    "\n",
    "    # NORMALIZE\n",
    "    if norm_factor is not None:\n",
    "        d /= norm_factor\n",
    "\n",
    "    return  d\n",
    "\n",
    "def get_delta_dim(df_name, landmark1, landmark2, dim, norm_factor=None):\n",
    "    delta = df_name[f'{dim}_{landmark1}'] - df_name[f'{dim}_{landmark2}']\n",
    "    # NORMALIZE\n",
    "    if norm_factor is not None:\n",
    "        delta /= norm_factor\n",
    "    return  delta\n",
    "\n",
    "\n",
    "def get_frames_around_event(fn_video, frame_number, n_neighbor_frames):\n",
    "    st = frame_number - n_neighbor_frames\n",
    "    ed = frame_number + n_neighbor_frames + 1\n",
    "    frame_numbers = range(st, ed)\n",
    "\n",
    "    extracted_frames = []\n",
    "    cap = cv2.VideoCapture(fn_video)\n",
    "\n",
    "    for frame_number in frame_numbers:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            extracted_frames.append(frame)\n",
    "    cap.release()\n",
    "        \n",
    "    return extracted_frames\n",
    "\n",
    "\n",
    "def create_video_from_frames(fn_video, extracted_frames):\n",
    "    out = None\n",
    "    if extracted_frames:\n",
    "        height, width, _ = extracted_frames[0].shape\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Codec for MP4 video\n",
    "        out = cv2.VideoWriter(fn_video, fourcc, 30.0, (width, height))\n",
    "        for frame in extracted_frames:\n",
    "            out.write(frame)\n",
    "        out.release()\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def extract_coordinates(cap, fn_video, show_video=False, verbose=True):\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Extracting coordinates for: {fn_video}\")\n",
    "    mp_drawing = mp.solutions.drawing_utils  # Drawing helpers\n",
    "    mp_holistic = mp.solutions.holistic  # Mediapipe Solutions\n",
    "\n",
    "    columns = [\"fn_video\", \"frame_number\"]\n",
    "    num_coords_face = 468\n",
    "    num_coords_hand = 21\n",
    "\n",
    "    # generate columns names\n",
    "    for val in range(0, num_coords_face):\n",
    "        columns += [\n",
    "            \"x_face{}\".format(val),\n",
    "            \"y_face{}\".format(val),\n",
    "            \"z_face{}\".format(val),\n",
    "            \"v_face{}\".format(val),\n",
    "        ]\n",
    "\n",
    "    for val in range(0, num_coords_hand):\n",
    "        columns += [\n",
    "            \"x_r_hand{}\".format(val),\n",
    "            \"y_r_hand{}\".format(val),\n",
    "            \"z_r_hand{}\".format(val),\n",
    "            \"v_r_hand{}\".format(val),\n",
    "        ]\n",
    "\n",
    "    df_coords = pd.DataFrame(columns=columns)\n",
    "\n",
    "    n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if verbose:\n",
    "        print(f\"Number of frames in video: {n_frames}\")\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        print(f\"Frames per second: {fps}\")\n",
    "        video_length = n_frames / fps\n",
    "        print(f\"Video length: {video_length} seconds\")\n",
    "    pbar = tqdm(total=n_frames)\n",
    "\n",
    "    # Initiate holistic model\n",
    "    i_frame = 0\n",
    "    with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5, min_tracking_confidence=0.5\n",
    "    ) as holistic:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            i_frame += 1\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "            # Recolor Feed\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = holistic.process(\n",
    "                image\n",
    "            )\n",
    "\n",
    "            # Recolor image back to BGR for rendering\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # 4. Pose Detections\n",
    "            if show_video:\n",
    "                # Draw face landmarks\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    results.face_landmarks,\n",
    "                    mp_holistic.FACEMESH_TESSELATION,\n",
    "                    mp_drawing.DrawingSpec(\n",
    "                        color=(80, 110, 10), thickness=1, circle_radius=1\n",
    "                    ),\n",
    "                    mp_drawing.DrawingSpec(\n",
    "                        color=(80, 256, 121), thickness=1, circle_radius=1\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "                # Right hand landmarks\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    results.right_hand_landmarks,\n",
    "                    mp_holistic.HAND_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(\n",
    "                        color=(80, 22, 10), thickness=2, circle_radius=4\n",
    "                    ),\n",
    "                    mp_drawing.DrawingSpec(\n",
    "                        color=(80, 44, 121), thickness=2, circle_radius=2\n",
    "                    ),\n",
    "                )\n",
    "                # Pose landmarks\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    results.pose_landmarks,\n",
    "                    mp_holistic.POSE_CONNECTIONS,\n",
    "                    mp_drawing.DrawingSpec(\n",
    "                        color=(245, 117, 66), thickness=2, circle_radius=4\n",
    "                    ),\n",
    "                    mp_drawing.DrawingSpec(\n",
    "                        color=(245, 66, 230), thickness=2, circle_radius=2\n",
    "                    ),\n",
    "                )\n",
    "                cv2.imshow(\"cued_estimated\", image)\n",
    "\n",
    "            # Export coordinates\n",
    "            if results.face_landmarks is not None:\n",
    "                face = results.face_landmarks.landmark\n",
    "                face_row = list(\n",
    "                    np.array(\n",
    "                        [\n",
    "                            [\n",
    "                                landmark.x, landmark.y, landmark.z,\n",
    "                                landmark.visibility\n",
    "                            ]\n",
    "                            for landmark in face\n",
    "                        ]\n",
    "                    ).flatten()\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                face_row = [None] * 4\n",
    "            # Extract right hand landmarks\n",
    "            if results.right_hand_landmarks is not None:\n",
    "                r_hand = results.right_hand_landmarks.landmark\n",
    "                r_hand_row = list(\n",
    "                    np.array(\n",
    "                        [\n",
    "                            [\n",
    "                                landmark.x, landmark.y, landmark.z,\n",
    "                                landmark.visibility\n",
    "                            ]\n",
    "                            for landmark in r_hand\n",
    "                        ]\n",
    "                    ).flatten()\n",
    "                )\n",
    "            else:\n",
    "                r_hand_row = [None] * 4\n",
    "\n",
    "            # Create the row that will be written in the file\n",
    "            row = [fn_video, i_frame] + face_row + r_hand_row\n",
    "            curr_df = pd.DataFrame(dict(zip(columns, row)), index=[0])\n",
    "            # print(i_frame, curr_df)\n",
    "            df_coords = pd.concat([df_coords, curr_df], ignore_index=True)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "                print(\"WARNING!\" * 5)\n",
    "                print('break due to cv2.waitKey(10) & 0xFF == ord(\"q\"')\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # print(len(df_coords), n_frames)\n",
    "    assert n_frames - df_coords.shape[0] <= 1\n",
    "\n",
    "    return df_coords\n",
    "\n",
    "\n",
    "def get_index_pairs(property_type):\n",
    "    index_pairs = []\n",
    "    if property_type == 'shape':\n",
    "        index_pairs.extend([\n",
    "            (2, 4), (5, 8), (9, 12), (13, 16), (17, 20),\n",
    "            (4, 5), (4, 8), (8, 12), (7, 11), (6, 10), \n",
    "            (4, 12), (4, 16), (4, 20),  # Thumb to other fingertips\n",
    "            (5, 9), (9, 13)   # Finger bases\n",
    "        ])\n",
    "    elif property_type == 'position':\n",
    "        hand_indices = [8, 9, 12]  # index and middle fingers\n",
    "        face_indices = [130, 152, 94]  # right eye, chin, nose\n",
    "        for hand_index in hand_indices:\n",
    "            for face_index in face_indices:\n",
    "                index_pairs.append((hand_index, face_index))\n",
    "    return index_pairs\n",
    "\n",
    "def get_angle(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    Compute the angle between three points p1, p2, and p3.\n",
    "    \"\"\"\n",
    "    v1 = p1 - p2\n",
    "    v2 = p3 - p2\n",
    "    cosine_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    return np.degrees(angle)\n",
    "\n",
    "\n",
    "def extract_features(df_coords):\n",
    "    # Create the df of relevant features\n",
    "    df_features = pd.DataFrame()\n",
    "    df_features[\"fn_video\"] = df_coords[\"fn_video\"].copy()\n",
    "    df_features[\"frame_number\"] = df_coords[\"frame_number\"]\n",
    "\n",
    "    # Face width to normalize the distance\n",
    "    face_width = get_distance(df_coords, \"face234\", \"face454\").mean()\n",
    "    norm_factor = face_width\n",
    "    print(f\"Face width computed for normalization: {face_width}\")\n",
    "\n",
    "    # HAND-FACE DISTANCES AS FEATURES FOR POSITION DECODING\n",
    "    position_index_pairs = get_index_pairs(\"position\")\n",
    "    for hand_index, face_index in position_index_pairs:\n",
    "        dx = get_delta_dim(\n",
    "            df_coords,\n",
    "            f\"face{face_index}\",\n",
    "            f\"r_hand{hand_index}\",\n",
    "            \"x\",\n",
    "            norm_factor=norm_factor,\n",
    "        )\n",
    "\n",
    "        dy = get_delta_dim(\n",
    "            df_coords,\n",
    "            f\"face{face_index}\",\n",
    "            f\"r_hand{hand_index}\",\n",
    "            \"y\",\n",
    "            norm_factor=norm_factor,\n",
    "        )\n",
    "\n",
    "        # Handle division by zero or NaN\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            tan_angle = np.divide(dx, dy)\n",
    "            tan_angle = np.nan_to_num(tan_angle, nan=0.0, posinf=0.0, neginf=0.0)  # Replace NaN and infinities with 0\n",
    "        feature_name = f\"tan_angle_face{face_index}_r_hand{hand_index}\"\n",
    "        df_features[feature_name] = tan_angle\n",
    "\n",
    "    for hand_index, face_index in position_index_pairs:\n",
    "        feature_name = f\"distance_face{face_index}_r_hand{hand_index}\"\n",
    "        df_features[feature_name] = get_distance(\n",
    "            df_coords,\n",
    "            f\"face{face_index}\",\n",
    "            f\"r_hand{hand_index}\",\n",
    "            norm_factor=norm_factor,\n",
    "        )\n",
    "\n",
    "    # HAND-HAND DISTANCES AS FEATURES FOR SHAPE DECODING\n",
    "    shape_index_pairs = get_index_pairs(\"shape\")\n",
    "    for hand_index1, hand_index2 in shape_index_pairs:\n",
    "        feature_name = f\"distance_r_hand{hand_index1}_r_hand{hand_index2}\"\n",
    "        df_features[feature_name] = get_distance(\n",
    "            df_coords,\n",
    "            f\"r_hand{hand_index1}\",\n",
    "            f\"r_hand{hand_index2}\",\n",
    "            norm_factor=norm_factor,\n",
    "        )\n",
    "\n",
    "    # HAND-HAND ANGLES AS FEATURES FOR SHAPE DECODING\n",
    "    angle_pairs = [\n",
    "        #(4, 8, 12),  # Thumb, index, middle\n",
    "        (8, 12, 16)  # Index, middle, ring\n",
    "    ]\n",
    "    for p1, p2, p3 in angle_pairs:\n",
    "        feature_name = f\"angle_r_hand{p1}_r_hand{p2}_r_hand{p3}\"\n",
    "        df_features[feature_name] = df_coords.apply(\n",
    "            lambda row: get_angle(\n",
    "                row[[f\"x_r_hand{p1}\", f\"y_r_hand{p1}\"]],\n",
    "                row[[f\"x_r_hand{p2}\", f\"y_r_hand{p2}\"]],\n",
    "                row[[f\"x_r_hand{p3}\", f\"y_r_hand{p3}\"]]\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    # HAND-FACE ORIENTATION FEATURES FOR POSITION DECODING\n",
    "    for hand_index in [8, 9, 12]:  # Index and middle fingers\n",
    "        for face_index in [130, 152, 94]:  # Right eye, chin, nose\n",
    "            # Horizontal offset\n",
    "            feature_name = f\"offset_x_face{face_index}_r_hand{hand_index}\"\n",
    "            df_features[feature_name] = get_delta_dim(\n",
    "                df_coords,\n",
    "                f\"face{face_index}\",\n",
    "                f\"r_hand{hand_index}\",\n",
    "                \"x\",\n",
    "                norm_factor=norm_factor,\n",
    "            )\n",
    "\n",
    "            # Vertical offset\n",
    "            feature_name = f\"offset_y_face{face_index}_r_hand{hand_index}\"\n",
    "            df_features[feature_name] = get_delta_dim(\n",
    "                df_coords,\n",
    "                f\"face{face_index}\",\n",
    "                f\"r_hand{hand_index}\",\n",
    "                \"y\",\n",
    "                norm_factor=norm_factor,\n",
    "            )\n",
    "\n",
    "    # TEMPORAL FEATURES\n",
    "    for hand_index in [8, 9, 12]:  # Index and middle fingers\n",
    "        # Velocity (change in position)\n",
    "        feature_name = f\"velocity_x_r_hand{hand_index}\"\n",
    "        df_features[feature_name] = df_coords[f\"x_r_hand{hand_index}\"].diff()\n",
    "        feature_name = f\"velocity_y_r_hand{hand_index}\"\n",
    "        df_features[feature_name] = df_coords[f\"y_r_hand{hand_index}\"].diff()\n",
    "\n",
    "        # Acceleration (change in velocity)\n",
    "        feature_name = f\"acceleration_x_r_hand{hand_index}\"\n",
    "        df_features[feature_name] = df_features[f\"velocity_x_r_hand{hand_index}\"].diff()\n",
    "        feature_name = f\"acceleration_y_r_hand{hand_index}\"\n",
    "        df_features[feature_name] = df_features[f\"velocity_y_r_hand{hand_index}\"].diff()\n",
    "\n",
    "    ## Replace NaN and infinite values in the entire DataFrame\n",
    "    #df_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    #df_features.fillna(0, inplace=True)\n",
    "#\n",
    "    ## Normalize features\n",
    "    #scaler = StandardScaler()\n",
    "    #df_features_normalized = scaler.fit_transform(df_features.drop(columns=[\"fn_video\", \"frame_number\"]))\n",
    "    #df_features_normalized = pd.DataFrame(df_features_normalized, columns=df_features.columns[2:])\n",
    "    #df_features_normalized[\"fn_video\"] = df_features[\"fn_video\"]\n",
    "    #df_features_normalized[\"frame_number\"] = df_features[\"frame_number\"]\n",
    "\n",
    "    return df_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def setup_logging(loglevel):\n",
    "    \"\"\"Setup basic logging\n",
    "\n",
    "    Args:\n",
    "        loglevel (int): Minimum loglevel for emitting messages\n",
    "    \"\"\"\n",
    "    logformat = \"[%(asctime)s] %(levelname)s:%(name)s:%(message)s\"\n",
    "    logging.basicConfig(\n",
    "        level=loglevel, stream=sys.stdout, format=logformat,\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_predictions(model, df_features):\n",
    "    '''\n",
    "    model - sklean model\n",
    "    df_features - dataframe with n_samples X n_features\n",
    "    '''\n",
    "    X = df_features.to_numpy()\n",
    "\n",
    "    predicted_class, predicted_probs = [], []\n",
    "    for X_i in X:\n",
    "        if (None in X_i) or (np.nan in X_i) or any([xi!=xi for xi in X_i]):\n",
    "            predicted_c = None\n",
    "            predicted_p = None\n",
    "        else:\n",
    "            predicted_c = model.predict([X_i])[0]\n",
    "            predicted_p = model.predict_proba([X_i])[0]\n",
    "        predicted_class.append(predicted_c)\n",
    "        predicted_probs.append(predicted_p)\n",
    "\n",
    "    return np.asarray(predicted_probs, dtype=object), \\\n",
    "        np.asarray(predicted_class)\n",
    "\n",
    "\n",
    "def compute_velocity(df, landmark, fn=None):\n",
    "    frame_number = df['frame_number']\n",
    "    x = df['x_' + landmark].values\n",
    "    y = df['y_' + landmark].values\n",
    "    z = df['z_' + landmark].values\n",
    "\n",
    "    dx = np.gradient(x, frame_number)\n",
    "    dy = np.gradient(y, frame_number)\n",
    "    dz = np.gradient(z, frame_number)\n",
    "\n",
    "    dx2 = np.gradient(dx, frame_number)\n",
    "    dy2 = np.gradient(dy, frame_number)\n",
    "    dz2 = np.gradient(dz, frame_number)\n",
    "\n",
    "    v = np.sqrt(dx**2 + dy**2 + dz**2)\n",
    "    a = np.sqrt(dx2**2 + dy2**2 + dz2**2)\n",
    "\n",
    "    v_smoothed = savgol_filter(v, 9, 3) # window\n",
    "    a_smoothed = savgol_filter(a, 9, 3) # window\n",
    "\n",
    "    if fn is not None:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(v_smoothed, lw=3, color='k')\n",
    "        ax.plot(a_smoothed, lw=3, color='b')\n",
    "        ax.set_xlabel('Frame', fontsize=16)\n",
    "        ax.set_ylabel('Velocity', fontsize=16)\n",
    "        ax.set_ylim([-0.01, 0.01])\n",
    "        fig.savefig(fn + '.png')\n",
    "    return  v_smoothed, a_smoothed\n",
    "\n",
    "\n",
    "def get_phone_onsets(fn_textgrid):\n",
    "    times, labels = [], []\n",
    "\n",
    "    grid = textgrids.TextGrid(fn_textgrid)\n",
    "    phones = grid['phones']\n",
    "    for phone in phones:\n",
    "        if phone.text.transcode() != '':\n",
    "            times.append(phone.xmin)\n",
    "            labels.append(phone.text.transcode())\n",
    "\n",
    "    return times, labels\n",
    "\n",
    "\n",
    "def get_stimulus_string(fn_video):\n",
    "    fn_base = os.path.basename(fn_video)[:-4]\n",
    "    fn_stimulus = fn_base + '.txt'\n",
    "    fn_stimulus = os.path.join('ACSR/stimuli/words/mfa_in', fn_stimulus)\n",
    "    s = open(fn_stimulus, 'r').readlines()\n",
    "    return s[0].strip('\\n')\n",
    "\n",
    "\n",
    "def dict_phone_transcription():\n",
    "    # Megalex (key) to MFA (value) phone labels\n",
    "    d = {}\n",
    "    d['R'] = 'ʁ'\n",
    "    d['N'] = 'ɲ'\n",
    "    d['§'] = 'ɔ̃'\n",
    "    d['Z'] = 'ʒ'\n",
    "    d['5'] = 'ɛ̃'\n",
    "    d['E'] = 'ɛ'\n",
    "    d['9'] = 'œ'\n",
    "    d['8'] = 'ɥ'\n",
    "    d['S'] = 'ʃ'\n",
    "    d['O'] = 'ɔ'\n",
    "    d['2'] = 'ø'\n",
    "    d['g'] = 'ɟ'\n",
    "    d['g'] = 'ɡ'\n",
    "    d['@'] = 'ɑ̃'\n",
    "    d['8'] = 'ɥ'\n",
    "    return d\n",
    "\n",
    "def find_syllable_onsets(lpc_syllables, times_phones, labels_phones):\n",
    "    phones = labels_phones.copy()\n",
    "    d_phone_transcription = dict_phone_transcription()\n",
    "    #print(lpc_syllables)\n",
    "    #[print(p, t) for p, t in zip(phones, times_phones)]\n",
    "    #print('-'*100)\n",
    "    times = []\n",
    "    for syllable in lpc_syllables:\n",
    "        first_phone = syllable[0]\n",
    "        if first_phone in d_phone_transcription.keys():\n",
    "            first_phone = d_phone_transcription[first_phone]\n",
    "        for i, phone in enumerate(phones):\n",
    "            if first_phone == phone:\n",
    "                times.append(times_phones[i])\n",
    "                del phones[i]\n",
    "                del times_phones[i]\n",
    "                break\n",
    "    return times\n",
    "\n",
    "\n",
    "def get_syllable_onset_frames_from_lpc_file(fn_video):\n",
    "    fn_base = os.path.basename(fn_video)[:-4]\n",
    "\n",
    "    # Get LPC parsing of stimulus, into separate SYLLABLES\n",
    "    # (MFA is for ALL phones and we need to know which phones are at the beginning of each syllable)\n",
    "    fn_lpc_parsing = fn_base + '.lpc'\n",
    "    fn_lpc_parsing = os.path.join('ACSR/stimuli/words/txt', fn_lpc_parsing)\n",
    "    lpc_syllables = open(fn_lpc_parsing, 'r').readlines()[0].strip('\\n').split()\n",
    "\n",
    "    return lpc_syllables\n",
    "\n",
    "    return \n",
    "def get_syllable_onset_frames_from_mfa(fn_video, lpc_syllables):\n",
    "\n",
    "    # Load video and get number of frames per second (fps)\n",
    "    cap = load_video(fn_video)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) # frames per second\n",
    "    assert fps > 0; 'Frames per seconds is not a positive number'\n",
    "\n",
    "    # Load corresponing TextGrid file\n",
    "    fn_base = os.path.basename(fn_video)[:-4]\n",
    "    fn_textgrid = fn_base + '.TextGrid'\n",
    "    fn_textgrid = os.path.join('../stimuli/words/mfa_out', fn_textgrid)\n",
    "\n",
    "    # Get LPC parsing of stimulus, into separate SYLLABLES\n",
    "    # (MFA is for ALL phones and we need to know which phones are at the beginning of each syllable)\n",
    "    #fn_lpc_parsing = fn_base + '.lpc'\n",
    "    #fn_lpc_parsing = os.path.join('../stimuli/words/txt', fn_lpc_parsing)\n",
    "    #lpc_syllables = open(fn_lpc_parsing, 'r').readlines()[0].strip('\\n').split()\n",
    "\n",
    "    # PHONE onests in seconds from MFA\n",
    "    onset_secs_phones_mfa, labels_phones_textgrid = get_phone_onsets(fn_textgrid)\n",
    "    print(onset_secs_phones_mfa, labels_phones_textgrid)\n",
    "    # SYLLABLE ONSET from MFA based on the onset of their FIRST PHONE\n",
    "    onset_secs_syllables_mfa = find_syllable_onsets(lpc_syllables, # in seconds\n",
    "                                                    onset_secs_phones_mfa,\n",
    "                                                    labels_phones_textgrid)\n",
    "    onset_frames_syllables_mfa = [int(t*fps) for t in onset_secs_syllables_mfa] # in frames\n",
    "\n",
    "    return onset_frames_syllables_mfa\n",
    "\n",
    "\n",
    "\n",
    "def find_onsets_based_on_extrema(time_series,\n",
    "                                 n_syllables=None,\n",
    "                                 onset_frames_syllables_mfa=None,\n",
    "                                 thresh=None): # condition: time_series > thresh\n",
    "\n",
    "    if onset_frames_syllables_mfa is not None: \n",
    "        onset_frames_syllables_mfa = np.asarray(onset_frames_syllables_mfa)\n",
    "\n",
    "    # find extrema\n",
    "    onset_frames_extrema = argrelextrema(time_series, np.greater)[0]\n",
    "    # Threshold\n",
    "    if thresh is not None:\n",
    "        onset_frames_extrema = np.asarray([onset_frame for onset_frame in onset_frames_extrema if time_series[onset_frame]>thresh])\n",
    "\n",
    "    onset_frames_extrema_temp = onset_frames_extrema.copy()\n",
    "    onset_frames_picked = []\n",
    "    if onset_frames_syllables_mfa is not None: # use MFA onsets to constrain the solution\n",
    "        if len(onset_frames_syllables_mfa) == len(onset_frames_extrema_temp):\n",
    "            onset_frames_picked = onset_frames_extrema_temp\n",
    "        else:\n",
    "            for i_frame, onset_frame_syl_mfa in enumerate(onset_frames_syllables_mfa):\n",
    "                # Find extremum that is nearest to current MFA onset\n",
    "                delta = np.abs(onset_frames_extrema_temp - onset_frame_syl_mfa)\n",
    "                IX_onset_frame_extremum_nearest_mfa = np.argmin(delta)\n",
    "                onset_frame_extremum_nearest_mfa = onset_frames_extrema_temp[IX_onset_frame_extremum_nearest_mfa]\n",
    "                onset_frames_picked.append(onset_frame_extremum_nearest_mfa)\n",
    "                # Remove past indexes, in order to make sure the next onset frame is in the future\n",
    "                onset_frames_extrema_temp = onset_frames_extrema_temp[onset_frames_extrema_temp > onset_frame_extremum_nearest_mfa]\n",
    "                if len(onset_frames_extrema_temp)==0:\n",
    "                    while len(onset_frames_picked) < len(onset_frames_syllables_mfa): # Fill None values if not enough identified extrema\n",
    "                        onset_frames_picked.append(None)\n",
    "                    break\n",
    "    else:\n",
    "        IXs = np.argpartition(onset_frames_extrema, -n_syllables)[-n_syllables:]\n",
    "        onset_frames_picked = list(onset_frames_extrema[IXs])\n",
    "\n",
    "    return onset_frames_picked, onset_frames_extrema\n",
    "\n",
    "def scale_velocity(velocity):\n",
    "    q25, q75 = np.percentile(velocity, 25), np.percentile(velocity, 75)\n",
    "    iqr = q75 - q25\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    velocity = np.clip(velocity, lower, upper)\n",
    "    velocity_scaled = minmax_scale(velocity)\n",
    "    return velocity_scaled\n",
    "\n",
    "\n",
    "def get_joint_measure(df_predictions_pos,\n",
    "                      df_predictions_shape,\n",
    "                      velocity_scaled,\n",
    "                      weight_velocity=1):\n",
    "\n",
    "    # MAX PROBABILITIES (POSITION AND SHAPE)\n",
    "    max_probs_pos = df_predictions_pos.copy().filter(regex=(\"p_class*\")).to_numpy().max(axis=1)\n",
    "    max_probs_shape = df_predictions_shape.copy().filter(regex=(\"p_class*\")).to_numpy().max(axis=1)\n",
    "    probs_product = max_probs_pos * max_probs_shape\n",
    "    # JOINT\n",
    "    joint_measure = (weight_velocity * (1-velocity_scaled) + probs_product)/(1+weight_velocity)\n",
    "    joint_measure_smoothed = savgol_filter(joint_measure, 15, 3) # window, smooth\n",
    "    # replace nans caused by smoothing with original values\n",
    "    is_nan_smoothed = np.isnan(joint_measure_smoothed)\n",
    "    joint_measure_smoothed[is_nan_smoothed] = joint_measure[is_nan_smoothed]\n",
    "\n",
    "    return joint_measure_smoothed\n",
    "\n",
    "\n",
    "def write_onsets_to_file(str_stimulus, lpc_syllables, onset_frames_picked, fn_txt):\n",
    "    \n",
    "    # HACK TO EQUALIZE THE NUMBER OF EXPECTED ONSETS (NUM SYLLABLES) AND THE ONE FOUND\n",
    "    if len(lpc_syllables) < len(onset_frames_picked): # REMOVE EXTRA ONSETS\n",
    "        onset_frames_picked = onset_frames_picked[:3]\n",
    "    for i_sy in range(len(lpc_syllables)-len(onset_frames_picked)): # ADD DUMMY ONSETS\n",
    "        onset_frames_picked = list(onset_frames_picked)\n",
    "        last_onset = onset_frames_picked[-1]\n",
    "        onset_frames_picked.append(last_onset + i_sy + 1)\n",
    "\n",
    "    assert len(lpc_syllables) == len(onset_frames_picked)\n",
    "\n",
    "    with open(fn_txt, 'w') as f:\n",
    "        f.write(f'{str_stimulus}\\n')\n",
    "        f.write('event,stimulus,frame_number\\n')\n",
    "        for (syllable, onset) in zip(lpc_syllables, onset_frames_picked):\n",
    "            f.write(f'SYLLABLE ONSET, {syllable}, {onset}\\n')\n",
    "    return None\n",
    "\n",
    "# FROM HAGAR\n",
    "\n",
    "def get_LPC_p(word):\n",
    "    lex = pd.read_csv(\"/home/yair/projects/ACSR/data/hagar/Lexique380.utf8.csv\")\n",
    "    lex = lex[(lex.ortho.str.contains('-| ') == False) & (lex.phon.str.contains('°') == False)]  # suppress schwa\n",
    "    lex = lex.drop_duplicates(subset='ortho', keep=\"first\")\n",
    "    lex = lex[['ortho','phon', 'p_cvcv','nbhomogr','cv-cv','syll']]\n",
    "    dic = lex.set_index('ortho').to_dict()\n",
    "\n",
    "    cv_dic = dic['cv-cv']\n",
    "    p_cv_dic = dic['syll']\n",
    "    phon_dic = dic['phon']    \n",
    "\n",
    "    dev_syl = pd.read_csv(\"/home/yair/projects/ACSR/data/hagar/lpc_syl_configurations.csv\")\n",
    "    dev_syl['lpc_n'] = dev_syl['LPC_config'].apply(lambda x: x.split('-'))\n",
    "    dev_syl['lpc_n'] = dev_syl['lpc_n'].apply(lambda x: len(x))\n",
    "    dic2 = dev_syl.set_index('spoken_config').to_dict()\n",
    "    \n",
    "    g_cv_dic = dic2['LPC_config']\n",
    "    \n",
    "    lpc_cv = get_LPC_cv(word, cv_dic, g_cv_dic)\n",
    "    \n",
    "    new_word = ''\n",
    "    phon = phon_dic[word]\n",
    "    if lpc_cv == cv_dic[word]:\n",
    "        return p_cv_dic[word]\n",
    "    else:\n",
    "        l_lpc = lpc_cv.split('-')\n",
    "        for syl in l_lpc:\n",
    "            new_word += phon[:len(syl)]+'-'\n",
    "            phon = phon[len(syl):]\n",
    "        return new_word[:-1]\n",
    "\n",
    "\n",
    "def get_LPC_cv(word, cv_dic, g_cv_dic):\n",
    "    \n",
    "\n",
    "    LPC_cv = ''\n",
    "    if word in cv_dic:\n",
    "        cv_lst = cv_dic[word].split('-')\n",
    "        for syl in cv_lst:\n",
    "            LPC_cv = LPC_cv + g_cv_dic[syl] + '-'\n",
    "        return LPC_cv[:-1]\n",
    "\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "def get_word_code(syll):\n",
    "    position = {'a': '0', 'o': '0', '9': '0', '5': '1', '2': '1', 'i': '2', '§': '2', '@': '2', 'E': '3', 'u': '3', 'O': '3', '1': '4', 'y': '4', 'e': '4'}\n",
    "    configuration = {'p': '0', 'd': '0', 'Z': '0', 'k': '1', 'v': '1', 'z': '1', 's': '2', 'R': '2', 'b': '3', 'n': '3', '8': '3', 't': '4', 'm': '4', 'f': '4', 'l': '5', 'S': '5', 'N': '5', 'w': '5', 'g': '6', 'j': '7', 'G': '7'}\n",
    "    try:\n",
    "        code_word = ''\n",
    "        if len(syll) == 1:\n",
    "            if syll in configuration:\n",
    "                code_word += configuration[syll]\n",
    "                code_word += '0'\n",
    "            else:\n",
    "                code_word += '4'\n",
    "                code_word += position[syll]\n",
    "        else:\n",
    "            for i in range (0,len(syll)):\n",
    "                if syll[i] in configuration:\n",
    "                    code_word += configuration[syll[i]]\n",
    "                else:\n",
    "                    code_word += position[syll[i]]\n",
    "        return code_word\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def shape_position_code(word):\n",
    "    code_word = \"\"\n",
    "    syll_lst = get_LPC_p(word).split(\"-\")\n",
    "    for syll in syll_lst:\n",
    "        code_word += get_word_code(syll) + '-'  \n",
    "    return code_word[:-1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acsr-MgaKDfGw-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
