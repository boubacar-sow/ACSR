{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load CSV files from a directory based on a filename pattern\n",
    "def load_csv_files(directory, filename_pattern, type=\"position\"):\n",
    "    files_data = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename_pattern in filename:\n",
    "            df = pd.read_csv(os.path.join(directory, filename))\n",
    "            df.fillna(0, inplace=True)\n",
    "            base_name = filename.split(f'_{type}_')[1].split('.csv')[0]\n",
    "            files_data[base_name] = df\n",
    "    return files_data\n",
    "\n",
    "# Find corresponding phoneme files based on the base names of position filenames\n",
    "def find_phoneme_files(directory, base_names):\n",
    "    phoneme_files = {}\n",
    "    for base_name in base_names:\n",
    "        phoneme_file = os.path.join(directory, f'{base_name}.csv')\n",
    "        if os.path.exists(phoneme_file):\n",
    "            phoneme_files[base_name] = phoneme_file\n",
    "    return phoneme_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================================================\n",
    "# Helper Functions\n",
    "# ==========================================================\n",
    "\n",
    "\n",
    "def pad_sequences(sequences, max_length, pad_value=0):\n",
    "    \"\"\"\n",
    "    Pad sequences to the maximum length.\n",
    "\n",
    "    Args:\n",
    "        sequences (list): List of sequences to pad.\n",
    "        max_length (int): Maximum length to pad to.\n",
    "        pad_value (int): Value to use for padding.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Padded sequences.\n",
    "    \"\"\"\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < max_length:\n",
    "            padding = np.full((max_length - len(seq), seq.shape[1]), pad_value)\n",
    "            padded_seq = np.vstack((seq, padding))\n",
    "        else:\n",
    "            padded_seq = seq[:max_length]\n",
    "        padded_sequences.append(padded_seq)\n",
    "    return np.array(padded_sequences)\n",
    "\n",
    "\n",
    "def extract_probabilities(data, columns):\n",
    "    \"\"\"\n",
    "    Extract and concatenate probabilities from multiple DataFrames.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of DataFrames.\n",
    "        columns (list): Columns to extract probabilities from.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Concatenated probabilities.\n",
    "    \"\"\"\n",
    "    data = [df.fillna(0) for df in data]\n",
    "    probs_list = [df[columns].to_numpy() for df in data]\n",
    "    return np.concatenate(probs_list, axis=0)\n",
    "\n",
    "\n",
    "def apply_phonotactic_rules(combinations):\n",
    "    \"\"\"\n",
    "    Apply phonotactic rules to filter invalid combinations.\n",
    "\n",
    "    Args:\n",
    "        combinations (list): List of phoneme combinations.\n",
    "\n",
    "    Returns:\n",
    "        list: Valid phoneme combinations.\n",
    "    \"\"\"\n",
    "    valid_combinations = []\n",
    "    for combination in combinations:\n",
    "        # Example phonotactic rules:\n",
    "        # 1. No consecutive vowels (e.g., \"ae\")\n",
    "        # 2. Certain consonant clusters are invalid (e.g., \"tl\")\n",
    "        if re.search(r\"[aeiouy]{2}\", combination):\n",
    "            continue  # Skip invalid combinations with consecutive vowels\n",
    "        if re.search(\n",
    "            r\"([s])\\1\", combination\n",
    "        ):  # Skip invalid combinations with double consonants\n",
    "            continue\n",
    "        valid_combinations.append(combination)\n",
    "    return valid_combinations\n",
    "\n",
    "\n",
    "def combine_sequences_with_padding(video_data):\n",
    "    \"\"\"\n",
    "    Combine sequences with padding to ensure uniform length.\n",
    "\n",
    "    Args:\n",
    "        video_data (dict): Dictionary containing video data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Padded input sequences (X) and padded labels (y).\n",
    "    \"\"\"\n",
    "    max_length = max(len(video_data[video][\"X\"]) for video in video_data)\n",
    "    X_padded = [\n",
    "        pad_sequences([video_data[video][\"X\"]], max_length)[0] for video in video_data\n",
    "    ]\n",
    "    y_padded = [\n",
    "        video_data[video][\"y\"]\n",
    "        + [phoneme_to_index[\" \"]] * (max_length - len(video_data[video][\"y\"]))\n",
    "        for video in video_data\n",
    "    ]\n",
    "    return X_padded, y_padded\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# Data Preparation Functions\n",
    "# ==========================================================\n",
    "\n",
    "# Load phoneme-to-index mapping\n",
    "with open(\n",
    "    r\"C:\\Users\\bouba\\Downloads\\CSF22\\CSF22\\phonelist.csv\", \"r\"\n",
    ") as file:\n",
    "    reader = csv.reader(file)\n",
    "    vocabulary_list = [row[0] for row in reader]\n",
    "\n",
    "\n",
    "phoneme_to_index = {phoneme: idx for idx, phoneme in enumerate(vocabulary_list)}\n",
    "index_to_phoneme = {idx: phoneme for phoneme, idx in phoneme_to_index.items()}\n",
    "phoneme_to_index[\" \"] = len(phoneme_to_index)\n",
    "index_to_phoneme[len(index_to_phoneme)] = \" \"\n",
    "\n",
    "\n",
    "def prepare_data_for_videos_no_sliding_windows(\n",
    "    hand_position_data, hand_shape_data, phoneme_files\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepare data for all videos without sliding windows.\n",
    "\n",
    "    Args:\n",
    "        hand_position_data (dict): Dictionary of hand position data.\n",
    "        hand_shape_data (dict): Dictionary of hand shape data.\n",
    "        phoneme_files (dict): Dictionary of phoneme file paths.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing combined probabilities and phoneme indices.\n",
    "    \"\"\"\n",
    "    all_videos_data = {}\n",
    "    for base_name in hand_position_data:\n",
    "        if base_name in phoneme_files:\n",
    "            position_df = hand_position_data[base_name]\n",
    "            shape_df = hand_shape_data[base_name]\n",
    "            phoneme_file = phoneme_files[base_name]\n",
    "\n",
    "            # Extract probabilities\n",
    "            hand_position_probs = extract_probabilities(\n",
    "                [position_df],\n",
    "                [\"p_class_1\", \"p_class_2\", \"p_class_3\", \"p_class_4\", \"p_class_5\"],\n",
    "            )\n",
    "            hand_shape_probs = extract_probabilities(\n",
    "                [shape_df],\n",
    "                [\n",
    "                    \"p_class_1\",\n",
    "                    \"p_class_2\",\n",
    "                    \"p_class_3\",\n",
    "                    \"p_class_4\",\n",
    "                    \"p_class_5\",\n",
    "                    \"p_class_6\",\n",
    "                    \"p_class_7\",\n",
    "                    \"p_class_8\",\n",
    "                ],\n",
    "            )\n",
    "            combined_probs = np.concatenate(\n",
    "                (hand_position_probs, hand_shape_probs), axis=1\n",
    "            )\n",
    "\n",
    "            # Read phoneme sequences\n",
    "            with open(phoneme_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                reader = csv.reader(f)\n",
    "                phoneme_sequence = [row[0] for row in reader]\n",
    "\n",
    "            # Convert phoneme sequence to indices\n",
    "            try:\n",
    "                phoneme_indices = [\n",
    "                    phoneme_to_index[phoneme] for phoneme in phoneme_sequence\n",
    "                ]\n",
    "            except KeyError:\n",
    "                print(phoneme_sequence)\n",
    "                print(base_name)\n",
    "                phoneme_indices = [\n",
    "                    phoneme_to_index[phoneme] for phoneme in phoneme_sequence\n",
    "                ]\n",
    "            all_videos_data[base_name] = {\"X\": combined_probs, \"y\": phoneme_indices}\n",
    "    return all_videos_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of position files: 30\n",
      "Number of shape files: 30\n",
      "Number of phoneme files: 30\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Main Script\n",
    "# ==========================================================\n",
    "\n",
    "# Directories\n",
    "data_dir = r'C:\\Users\\bouba\\OneDrive\\Documents\\ACSR\\ACSR\\output\\predictions'\n",
    "phoneme_dir = r'C:\\Users\\bouba\\Downloads\\CSF22\\CSF22\\CSF22_train\\train_labels'\n",
    "\n",
    "# Load position and shape data\n",
    "hand_position_data = load_csv_files(data_dir, 'predictions_rf_position', type='position')\n",
    "hand_shape_data = load_csv_files(data_dir, 'predictions_rf_shape', type='shape')\n",
    "\n",
    "# Find phoneme files\n",
    "base_names = hand_position_data.keys()\n",
    "phoneme_files = find_phoneme_files(phoneme_dir, base_names)\n",
    "\n",
    "# Print the number of files found\n",
    "print(f\"Number of position files: {len(hand_position_data)}\")\n",
    "print(f\"Number of shape files: {len(hand_shape_data)}\")\n",
    "print(f\"Number of phoneme files: {len(phoneme_files)}\")\n",
    "\n",
    "# Take only the first 5 videos for demonstration\n",
    "hand_position_data = {\n",
    "    key: hand_position_data[key] for key in list(hand_position_data.keys())\n",
    "}\n",
    "hand_shape_data = {\n",
    "    key: hand_shape_data[key] for key in list(hand_shape_data.keys())\n",
    "}\n",
    "phoneme_files = {key: phoneme_files[key] for key in list(phoneme_files.keys())}\n",
    "\n",
    "# Prepare data\n",
    "all_videos_data = prepare_data_for_videos_no_sliding_windows(\n",
    "    hand_position_data, hand_shape_data, phoneme_files\n",
    ")\n",
    "X_combined, y_combined = combine_sequences_with_padding(all_videos_data)\n",
    "\n",
    "# Convert phoneme sequences to tensors\n",
    "y_tensors = [\n",
    "    torch.tensor([index for index in video_data[\"y\"]], dtype=torch.long)\n",
    "    for video_data in all_videos_data.values()\n",
    "]\n",
    "all_videos_data = {\n",
    "    key: {\"X\": video_data[\"X\"], \"y\": y_tensors[i]}\n",
    "    for i, (key, video_data) in enumerate(all_videos_data.items())\n",
    "}\n",
    "\n",
    "# Combine all data into tensors\n",
    "X_combined = torch.tensor(np.array(X_combined), dtype=torch.float32) \n",
    "y_combined = torch.tensor(y_combined, dtype=torch.long)\n",
    "\n",
    "# Normalize data (optional)\n",
    "# X_combined = (X_combined - X_combined.mean()) / X_combined.std()\n",
    "\n",
    "# Final organized data\n",
    "all_videos_data = {\"X\": X_combined, \"y\": y_combined}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of train dataset 27\n",
      "Len of val dataset 3\n",
      "Batch X shape: torch.Size([4, 310, 13])\n",
      "Batch y shape: torch.Size([4, 310])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Function to split data into training and validation sets\n",
    "def train_val_split(data, train_ratio=0.9):\n",
    "    num_samples = len(data['X'])\n",
    "    split_idx = int(num_samples * train_ratio)\n",
    "    \n",
    "    train_data = {\n",
    "        'X': data['X'][:split_idx],\n",
    "        'y': data['y'][:split_idx]\n",
    "    }\n",
    "    val_data = {\n",
    "        'X': data['X'][split_idx:],\n",
    "        'y': data['y'][split_idx:]\n",
    "    }\n",
    "    return train_data, val_data\n",
    "\n",
    "# Convert data to DataLoader format\n",
    "def data_to_dataloader(data, batch_size=4, shuffle=True):\n",
    "    X_tensors = data['X']\n",
    "    y_tensors = data['y']\n",
    "    \n",
    "    # Create a TensorDataset with both inputs and labels\n",
    "    dataset = TensorDataset(X_tensors, y_tensors)\n",
    "    \n",
    "    # Create a DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "# Split data\n",
    "train_data, val_data = train_val_split(all_videos_data)\n",
    "\n",
    "# Prepare DataLoaders\n",
    "train_loader = data_to_dataloader(train_data, batch_size=4, shuffle=True)\n",
    "val_loader = data_to_dataloader(val_data, batch_size=4, shuffle=False)\n",
    "\n",
    "print(\"Len of train dataset\", len(train_data['X']))\n",
    "print(\"Len of val dataset\", len(val_data['X']))\n",
    "\n",
    "# Check the DataLoader output\n",
    "for batch_X, batch_y in train_loader:\n",
    "    print(\"Batch X shape:\", batch_X.shape)\n",
    "    print(\"Batch y shape:\", batch_y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 58.04133551461356\n",
      "Epoch 2/1000, Loss: 23.48119340624128\n",
      "Epoch 3/1000, Loss: 5.559428419385638\n",
      "Epoch 4/1000, Loss: 5.477286270686558\n",
      "Epoch 5/1000, Loss: 4.193204947880337\n",
      "Epoch 6/1000, Loss: 3.7326256888253346\n",
      "Epoch 7/1000, Loss: 3.757940803255354\n",
      "Epoch 8/1000, Loss: 3.6336957045963834\n",
      "Epoch 9/1000, Loss: 3.653700351715088\n",
      "Epoch 10/1000, Loss: 3.6141338688986644\n",
      "Epoch 11/1000, Loss: 3.6076059682028636\n",
      "Epoch 12/1000, Loss: 3.617931536265782\n",
      "Epoch 13/1000, Loss: 3.589280469076974\n",
      "Epoch 14/1000, Loss: 3.5846245970044817\n",
      "Epoch 15/1000, Loss: 3.585651772362845\n",
      "Epoch 16/1000, Loss: 3.5692785467420305\n",
      "Epoch 17/1000, Loss: 3.553865671157837\n",
      "Epoch 18/1000, Loss: 3.5384830747331892\n",
      "Epoch 19/1000, Loss: 3.530240399496896\n",
      "Epoch 20/1000, Loss: 3.5171380043029785\n",
      "Epoch 21/1000, Loss: 3.4903359413146973\n",
      "Epoch 22/1000, Loss: 3.4694502694266185\n",
      "Epoch 23/1000, Loss: 3.435734748840332\n",
      "Epoch 24/1000, Loss: 3.4328765869140625\n",
      "Epoch 25/1000, Loss: 3.384185654776437\n",
      "Epoch 26/1000, Loss: 3.3339692524501254\n",
      "Epoch 27/1000, Loss: 3.3109326362609863\n",
      "Epoch 28/1000, Loss: 3.2999019282204762\n",
      "Epoch 29/1000, Loss: 3.265575408935547\n",
      "Epoch 30/1000, Loss: 3.251512050628662\n",
      "Epoch 31/1000, Loss: 3.2411389691489085\n",
      "Epoch 32/1000, Loss: 3.2332994597298756\n",
      "Epoch 33/1000, Loss: 3.212538412639073\n",
      "Epoch 34/1000, Loss: 3.2155071667262485\n",
      "Epoch 35/1000, Loss: 3.207538332257952\n",
      "Epoch 36/1000, Loss: 3.211240530014038\n",
      "Epoch 37/1000, Loss: 3.205664907182966\n",
      "Epoch 38/1000, Loss: 3.183462177004133\n",
      "Epoch 39/1000, Loss: 3.184774739401681\n",
      "Epoch 40/1000, Loss: 3.175695078713553\n",
      "Epoch 41/1000, Loss: 3.184126513344901\n",
      "Epoch 42/1000, Loss: 3.1682335308619907\n",
      "Epoch 43/1000, Loss: 3.1881303787231445\n",
      "Epoch 44/1000, Loss: 3.1592233180999756\n",
      "Epoch 45/1000, Loss: 3.1635228225163052\n",
      "Epoch 46/1000, Loss: 3.150235755102975\n",
      "Epoch 47/1000, Loss: 3.141693796430315\n",
      "Epoch 48/1000, Loss: 3.1200495788029263\n",
      "Epoch 49/1000, Loss: 3.09295231955392\n",
      "Epoch 50/1000, Loss: 3.072218656539917\n",
      "Epoch 51/1000, Loss: 3.0677304608481273\n",
      "Epoch 52/1000, Loss: 3.0571818692343578\n",
      "Epoch 53/1000, Loss: 3.0408238683428084\n",
      "Epoch 54/1000, Loss: 3.0296501772744313\n",
      "Epoch 55/1000, Loss: 3.0059922763279507\n",
      "Epoch 56/1000, Loss: 2.997718708855765\n",
      "Epoch 57/1000, Loss: 2.9958876882280623\n",
      "Epoch 58/1000, Loss: 2.9684708459036693\n",
      "Epoch 59/1000, Loss: 2.9751923765454973\n",
      "Epoch 60/1000, Loss: 2.965250185557774\n",
      "Epoch 61/1000, Loss: 2.9643171514783586\n",
      "Epoch 62/1000, Loss: 2.952801670346941\n",
      "Epoch 63/1000, Loss: 2.9529430185045515\n",
      "Epoch 64/1000, Loss: 2.94921875\n",
      "Epoch 65/1000, Loss: 2.940652847290039\n",
      "Epoch 66/1000, Loss: 2.9369241169520786\n",
      "Epoch 67/1000, Loss: 2.9448058945792064\n",
      "Epoch 68/1000, Loss: 2.954494374138968\n",
      "Epoch 69/1000, Loss: 2.9483211040496826\n",
      "Epoch 70/1000, Loss: 2.934441225869315\n",
      "Epoch 71/1000, Loss: 2.9364759581429616\n",
      "Epoch 72/1000, Loss: 2.928723539624895\n",
      "Epoch 73/1000, Loss: 2.916203396660941\n",
      "Epoch 74/1000, Loss: 2.9183477674211775\n",
      "Epoch 75/1000, Loss: 2.918396472930908\n",
      "Epoch 76/1000, Loss: 2.908916030611311\n",
      "Epoch 77/1000, Loss: 2.9061104229518344\n",
      "Epoch 78/1000, Loss: 2.901094845363072\n",
      "Epoch 79/1000, Loss: 2.8987881456102644\n",
      "Epoch 80/1000, Loss: 2.8851101398468018\n",
      "Epoch 81/1000, Loss: 2.895869391305106\n",
      "Epoch 82/1000, Loss: 2.8907217979431152\n",
      "Epoch 83/1000, Loss: 2.894018922533308\n",
      "Epoch 84/1000, Loss: 2.8789261749812534\n",
      "Epoch 85/1000, Loss: 2.8885312420981273\n",
      "Epoch 86/1000, Loss: 2.8826448576790944\n",
      "Epoch 87/1000, Loss: 2.8985320159367154\n",
      "Epoch 88/1000, Loss: 2.8813470772334506\n",
      "Epoch 89/1000, Loss: 2.8834061282021657\n",
      "Epoch 90/1000, Loss: 2.8912151200430736\n",
      "Epoch 91/1000, Loss: 2.8726414271763394\n",
      "Epoch 92/1000, Loss: 2.8641234125409807\n",
      "Epoch 93/1000, Loss: 2.8486166340964183\n",
      "Epoch 94/1000, Loss: 2.876023428780692\n",
      "Epoch 95/1000, Loss: 2.867455039705549\n",
      "Epoch 96/1000, Loss: 2.8632896968296597\n",
      "Epoch 97/1000, Loss: 2.854450123650687\n",
      "Epoch 98/1000, Loss: 2.8555171149117604\n",
      "Epoch 99/1000, Loss: 2.8526551723480225\n",
      "Epoch 100/1000, Loss: 2.8593412808009555\n",
      "Epoch 101/1000, Loss: 2.861532211303711\n",
      "Epoch 102/1000, Loss: 2.861224515097482\n",
      "Epoch 103/1000, Loss: 2.8620830604008267\n",
      "Epoch 104/1000, Loss: 2.8496364865984236\n",
      "Epoch 105/1000, Loss: 2.834700720650809\n",
      "Epoch 106/1000, Loss: 2.840038367680141\n",
      "Epoch 107/1000, Loss: 2.8413799490247453\n",
      "Epoch 108/1000, Loss: 2.8388138839176724\n",
      "Epoch 109/1000, Loss: 2.8371973718915666\n",
      "Epoch 110/1000, Loss: 2.836562020438058\n",
      "Epoch 111/1000, Loss: 2.8145205633980885\n",
      "Epoch 112/1000, Loss: 2.8257087639399936\n",
      "Epoch 113/1000, Loss: 2.8381286348615373\n",
      "Epoch 114/1000, Loss: 2.814302614756993\n",
      "Epoch 115/1000, Loss: 2.8381075177873885\n",
      "Epoch 116/1000, Loss: 2.8315394265311107\n",
      "Epoch 117/1000, Loss: 2.860396691731044\n",
      "Epoch 118/1000, Loss: 2.8817614827837263\n",
      "Epoch 119/1000, Loss: 2.9007885115487233\n",
      "Epoch 120/1000, Loss: 2.894277742930821\n",
      "Epoch 121/1000, Loss: 2.8862526416778564\n",
      "Epoch 122/1000, Loss: 2.8674328327178955\n",
      "Epoch 123/1000, Loss: 2.848506348473685\n",
      "Epoch 124/1000, Loss: 2.8427229608808244\n",
      "Epoch 125/1000, Loss: 2.8479031154087613\n",
      "Epoch 126/1000, Loss: 2.848424162183489\n",
      "Epoch 127/1000, Loss: 2.8525631768362865\n",
      "Epoch 128/1000, Loss: 2.834350722176688\n",
      "Epoch 129/1000, Loss: 2.8372794900621687\n",
      "Epoch 130/1000, Loss: 2.843256984438215\n",
      "Epoch 131/1000, Loss: 2.831772838320051\n",
      "Epoch 132/1000, Loss: 2.8365869522094727\n",
      "Epoch 133/1000, Loss: 2.8371952261243547\n",
      "Epoch 134/1000, Loss: 2.810180425643921\n",
      "Epoch 135/1000, Loss: 2.826096909386771\n",
      "Epoch 136/1000, Loss: 2.8221985271998813\n",
      "Epoch 137/1000, Loss: 2.815438611166818\n",
      "Epoch 138/1000, Loss: 2.8194545677730014\n",
      "Epoch 139/1000, Loss: 2.8088249138423373\n",
      "Epoch 140/1000, Loss: 2.806830474308559\n",
      "Epoch 141/1000, Loss: 2.806925126484462\n",
      "Epoch 142/1000, Loss: 2.8108645166669572\n",
      "Epoch 143/1000, Loss: 2.790127311434065\n",
      "Epoch 144/1000, Loss: 2.7974733965737477\n",
      "Epoch 145/1000, Loss: 2.798159803662981\n",
      "Epoch 146/1000, Loss: 2.7972635541643416\n",
      "Epoch 147/1000, Loss: 2.7934818949018205\n",
      "Epoch 148/1000, Loss: 2.797172818865095\n",
      "Epoch 149/1000, Loss: 2.765404769352504\n",
      "Epoch 150/1000, Loss: 2.7648725169045583\n",
      "Epoch 151/1000, Loss: 2.7647342000688826\n",
      "Epoch 152/1000, Loss: 2.7516625949314664\n",
      "Epoch 153/1000, Loss: 2.747086082186018\n",
      "Epoch 154/1000, Loss: 2.76257586479187\n",
      "Epoch 155/1000, Loss: 2.7516653878348216\n",
      "Epoch 156/1000, Loss: 2.7326419353485107\n",
      "Epoch 157/1000, Loss: 2.744962385722569\n",
      "Epoch 158/1000, Loss: 2.7361579281943187\n",
      "Epoch 159/1000, Loss: 2.7296953541891917\n",
      "Epoch 160/1000, Loss: 2.7052276134490967\n",
      "Epoch 161/1000, Loss: 2.7203346320561\n",
      "Epoch 162/1000, Loss: 2.7040028231484547\n",
      "Epoch 163/1000, Loss: 2.7146882670266286\n",
      "Epoch 164/1000, Loss: 2.709494182041713\n",
      "Epoch 165/1000, Loss: 2.6929967403411865\n",
      "Epoch 166/1000, Loss: 2.7281642300742015\n",
      "Epoch 167/1000, Loss: 2.6997081211635043\n",
      "Epoch 168/1000, Loss: 2.6815864018031528\n",
      "Epoch 169/1000, Loss: 2.676670551300049\n",
      "Epoch 170/1000, Loss: 2.645232949938093\n",
      "Epoch 171/1000, Loss: 2.6458604676382884\n",
      "Epoch 172/1000, Loss: 2.6416268008095876\n",
      "Epoch 173/1000, Loss: 2.6318323952811107\n",
      "Epoch 174/1000, Loss: 2.6174986362457275\n",
      "Epoch 175/1000, Loss: 2.625394105911255\n",
      "Epoch 176/1000, Loss: 2.6184465203966414\n",
      "Epoch 177/1000, Loss: 2.603459596633911\n",
      "Epoch 178/1000, Loss: 2.591506004333496\n",
      "Epoch 179/1000, Loss: 2.576266050338745\n",
      "Epoch 180/1000, Loss: 2.582268408366612\n",
      "Epoch 181/1000, Loss: 2.5967742715563094\n",
      "Epoch 182/1000, Loss: 2.623983008520944\n",
      "Epoch 183/1000, Loss: 2.6337759835379466\n",
      "Epoch 184/1000, Loss: 2.6169376373291016\n",
      "Epoch 185/1000, Loss: 2.593928779874529\n",
      "Epoch 186/1000, Loss: 2.5515437807355608\n",
      "Epoch 187/1000, Loss: 2.564774751663208\n",
      "Epoch 188/1000, Loss: 2.531522648675101\n",
      "Epoch 189/1000, Loss: 2.536449296133859\n",
      "Epoch 190/1000, Loss: 2.510342529841832\n",
      "Epoch 191/1000, Loss: 2.520869936261858\n",
      "Epoch 192/1000, Loss: 2.485187155859811\n",
      "Epoch 193/1000, Loss: 2.4723303658621654\n",
      "Epoch 194/1000, Loss: 2.4927638598850796\n",
      "Epoch 195/1000, Loss: 2.452636650630406\n",
      "Epoch 196/1000, Loss: 2.5320161070142473\n",
      "Epoch 197/1000, Loss: 2.4952165399278914\n",
      "Epoch 198/1000, Loss: 2.5028305734906877\n",
      "Epoch 199/1000, Loss: 2.4640664032527377\n",
      "Epoch 200/1000, Loss: 2.45180835042681\n",
      "Epoch 201/1000, Loss: 2.4305461985724315\n",
      "Epoch 202/1000, Loss: 2.455275229045323\n",
      "Epoch 203/1000, Loss: 2.443436247961862\n",
      "Epoch 204/1000, Loss: 2.3904698065349033\n",
      "Epoch 205/1000, Loss: 2.400318043572562\n",
      "Epoch 206/1000, Loss: 2.3721711124692644\n",
      "Epoch 207/1000, Loss: 2.3933108704430714\n",
      "Epoch 208/1000, Loss: 2.4365230969020297\n",
      "Epoch 209/1000, Loss: 2.3995934554508755\n",
      "Epoch 210/1000, Loss: 2.387563467025757\n",
      "Epoch 211/1000, Loss: 2.3395142214638844\n",
      "Epoch 212/1000, Loss: 2.345802903175354\n",
      "Epoch 213/1000, Loss: 2.3088784217834473\n",
      "Epoch 214/1000, Loss: 2.2949330806732178\n",
      "Epoch 215/1000, Loss: 2.2544970342091153\n",
      "Epoch 216/1000, Loss: 2.2815138953072682\n",
      "Epoch 217/1000, Loss: 2.2554440668651035\n",
      "Epoch 218/1000, Loss: 2.2281426191329956\n",
      "Epoch 219/1000, Loss: 2.237697090421404\n",
      "Epoch 220/1000, Loss: 2.237249118941171\n",
      "Epoch 221/1000, Loss: 2.2164181641169955\n",
      "Epoch 222/1000, Loss: 2.1900488478796825\n",
      "Epoch 223/1000, Loss: 2.179281370980399\n",
      "Epoch 224/1000, Loss: 2.194832478250776\n",
      "Epoch 225/1000, Loss: 2.1293775694710866\n",
      "Epoch 226/1000, Loss: 2.1509050130844116\n",
      "Epoch 227/1000, Loss: 2.1724819796425954\n",
      "Epoch 228/1000, Loss: 2.1666806084769115\n",
      "Epoch 229/1000, Loss: 2.130140100206648\n",
      "Epoch 230/1000, Loss: 2.1147569588252475\n",
      "Epoch 231/1000, Loss: 2.0942795617239818\n",
      "Epoch 232/1000, Loss: 2.0928337403706143\n",
      "Epoch 233/1000, Loss: 2.0398913281304494\n",
      "Epoch 234/1000, Loss: 2.0414023910249983\n",
      "Epoch 235/1000, Loss: 2.0277645587921143\n",
      "Epoch 236/1000, Loss: 2.0165394885199412\n",
      "Epoch 237/1000, Loss: 1.981064932686942\n",
      "Epoch 238/1000, Loss: 1.942191481590271\n",
      "Epoch 239/1000, Loss: 1.9299230064664568\n",
      "Epoch 240/1000, Loss: 1.9073251145226615\n",
      "Epoch 241/1000, Loss: 1.8871657678059168\n",
      "Epoch 242/1000, Loss: 1.8583564417702811\n",
      "Epoch 243/1000, Loss: 1.845788768359593\n",
      "Epoch 244/1000, Loss: 1.8897302831922258\n",
      "Epoch 245/1000, Loss: 1.8630563701902116\n",
      "Epoch 246/1000, Loss: 1.8435276576450892\n",
      "Epoch 247/1000, Loss: 1.8500742060797555\n",
      "Epoch 248/1000, Loss: 1.8101732390267509\n",
      "Epoch 249/1000, Loss: 1.8249612365450179\n",
      "Epoch 250/1000, Loss: 2.0797165972845897\n",
      "Epoch 251/1000, Loss: 2.239421078136989\n",
      "Epoch 252/1000, Loss: 2.88771459034511\n",
      "Epoch 253/1000, Loss: 2.7842466831207275\n",
      "Epoch 254/1000, Loss: 2.6372731072562083\n",
      "Epoch 255/1000, Loss: 2.5606882912772044\n",
      "Epoch 256/1000, Loss: 2.422255822590419\n",
      "Epoch 257/1000, Loss: 2.3104825019836426\n",
      "Epoch 258/1000, Loss: 2.2434684889657155\n",
      "Epoch 259/1000, Loss: 2.1797193118504117\n",
      "Epoch 260/1000, Loss: 2.1205976009368896\n",
      "Epoch 261/1000, Loss: 2.0627405643463135\n",
      "Epoch 262/1000, Loss: 2.0267908913748607\n",
      "Epoch 263/1000, Loss: 2.005529318537031\n",
      "Epoch 264/1000, Loss: 1.9609345197677612\n",
      "Epoch 265/1000, Loss: 1.92110504422869\n",
      "Epoch 266/1000, Loss: 1.923173291342599\n",
      "Epoch 267/1000, Loss: 1.9118167843137468\n",
      "Epoch 268/1000, Loss: 1.8774998358317785\n",
      "Epoch 269/1000, Loss: 1.8370741946356637\n",
      "Epoch 270/1000, Loss: 1.8153718880244665\n",
      "Epoch 271/1000, Loss: 1.8116387128829956\n",
      "Epoch 272/1000, Loss: 1.7803271497998918\n",
      "Epoch 273/1000, Loss: 1.7712321792330061\n",
      "Epoch 274/1000, Loss: 1.7583468300955636\n",
      "Epoch 275/1000, Loss: 1.730007188660758\n",
      "Epoch 276/1000, Loss: 1.7285322972706385\n",
      "Epoch 277/1000, Loss: 1.6883310760770525\n",
      "Epoch 278/1000, Loss: 1.719166874885559\n",
      "Epoch 279/1000, Loss: 1.661462766783578\n",
      "Epoch 280/1000, Loss: 1.670221209526062\n",
      "Epoch 281/1000, Loss: 1.6858762843268258\n",
      "Epoch 282/1000, Loss: 1.6582895006452287\n",
      "Epoch 283/1000, Loss: 1.6312599352427892\n",
      "Epoch 284/1000, Loss: 1.555657982826233\n",
      "Epoch 285/1000, Loss: 1.5123574222837175\n",
      "Epoch 286/1000, Loss: 1.4987471614565169\n",
      "Epoch 287/1000, Loss: 1.4518004485539027\n",
      "Epoch 288/1000, Loss: 1.4187555653708321\n",
      "Epoch 289/1000, Loss: 1.4009611776896886\n",
      "Epoch 290/1000, Loss: 1.3737372841153825\n",
      "Epoch 291/1000, Loss: 1.3616994534220015\n",
      "Epoch 292/1000, Loss: 1.345672300883702\n",
      "Epoch 293/1000, Loss: 1.333511233329773\n",
      "Epoch 294/1000, Loss: 1.316534127507891\n",
      "Epoch 295/1000, Loss: 1.3067105923380171\n",
      "Epoch 296/1000, Loss: 1.270606245313372\n",
      "Epoch 297/1000, Loss: 1.2269872767584664\n",
      "Epoch 298/1000, Loss: 1.2106654473713465\n",
      "Epoch 299/1000, Loss: 1.1940498437200273\n",
      "Epoch 300/1000, Loss: 1.1817815474101476\n",
      "Epoch 301/1000, Loss: 1.1609825577054704\n",
      "Epoch 302/1000, Loss: 1.1520125355039323\n",
      "Epoch 303/1000, Loss: 1.1504757404327393\n",
      "Epoch 304/1000, Loss: 1.1153256808008467\n",
      "Epoch 305/1000, Loss: 1.1514027629579817\n",
      "Epoch 306/1000, Loss: 1.318932328905378\n",
      "Epoch 307/1000, Loss: 1.3367438997541154\n",
      "Epoch 308/1000, Loss: 1.300406473023551\n",
      "Epoch 309/1000, Loss: 1.225111484527588\n",
      "Epoch 310/1000, Loss: 1.2266064882278442\n",
      "Epoch 311/1000, Loss: 1.406711425100054\n",
      "Epoch 312/1000, Loss: 1.3750131300517492\n",
      "Epoch 313/1000, Loss: 1.3187803711209978\n",
      "Epoch 314/1000, Loss: 1.2586396592003959\n",
      "Epoch 315/1000, Loss: 1.2254965135029383\n",
      "Epoch 316/1000, Loss: 1.1623270767075675\n",
      "Epoch 317/1000, Loss: 1.1143256000110082\n",
      "Epoch 318/1000, Loss: 1.0859759194510323\n",
      "Epoch 319/1000, Loss: 1.0536899822098869\n",
      "Epoch 320/1000, Loss: 1.0140312995229448\n",
      "Epoch 321/1000, Loss: 0.9923002890178135\n",
      "Epoch 322/1000, Loss: 0.9458296895027161\n",
      "Epoch 323/1000, Loss: 0.9082824162074498\n",
      "Epoch 324/1000, Loss: 0.9075560144015721\n",
      "Epoch 325/1000, Loss: 0.8809121165956769\n",
      "Epoch 326/1000, Loss: 0.8562590735299247\n",
      "Epoch 327/1000, Loss: 0.8399853706359863\n",
      "Epoch 328/1000, Loss: 0.8071289913994926\n",
      "Epoch 329/1000, Loss: 0.7826403549739293\n",
      "Epoch 330/1000, Loss: 0.7772278019360134\n",
      "Epoch 331/1000, Loss: 0.7539083531924656\n",
      "Epoch 332/1000, Loss: 0.7349155928407397\n",
      "Epoch 333/1000, Loss: 0.7378861648695809\n",
      "Epoch 334/1000, Loss: 0.7313217265265328\n",
      "Epoch 335/1000, Loss: 0.7185518230710711\n",
      "Epoch 336/1000, Loss: 0.7065850411142621\n",
      "Epoch 337/1000, Loss: 0.7092320152691433\n",
      "Epoch 338/1000, Loss: 0.6972983224051339\n",
      "Epoch 339/1000, Loss: 0.6971412471362523\n",
      "Epoch 340/1000, Loss: 0.6981706874711173\n",
      "Epoch 341/1000, Loss: 0.6885346089090619\n",
      "Epoch 342/1000, Loss: 0.6998596361705235\n",
      "Epoch 343/1000, Loss: 0.6758934855461121\n",
      "Epoch 344/1000, Loss: 0.6618039608001709\n",
      "Epoch 345/1000, Loss: 0.6486711757523673\n",
      "Epoch 346/1000, Loss: 0.6593363625662667\n",
      "Epoch 347/1000, Loss: 0.6416181198188237\n",
      "Epoch 348/1000, Loss: 0.6134503654071263\n",
      "Epoch 349/1000, Loss: 0.5954826559339251\n",
      "Epoch 350/1000, Loss: 0.5784730996404376\n",
      "Epoch 351/1000, Loss: 0.5651542799813407\n",
      "Epoch 352/1000, Loss: 0.5533701479434967\n",
      "Epoch 353/1000, Loss: 0.5440397730895451\n",
      "Epoch 354/1000, Loss: 0.5375108633722577\n",
      "Epoch 355/1000, Loss: 0.5126834171158927\n",
      "Epoch 356/1000, Loss: 0.5006435428346906\n",
      "Epoch 357/1000, Loss: 0.483829276902335\n",
      "Epoch 358/1000, Loss: 0.472256064414978\n",
      "Epoch 359/1000, Loss: 0.46266021047319683\n",
      "Epoch 360/1000, Loss: 0.4665392424379076\n",
      "Epoch 361/1000, Loss: 0.4618211729185922\n",
      "Epoch 362/1000, Loss: 0.46217343636921476\n",
      "Epoch 363/1000, Loss: 0.44729422671454294\n",
      "Epoch 364/1000, Loss: 0.4307843659605299\n",
      "Epoch 365/1000, Loss: 0.43801601018224445\n",
      "Epoch 366/1000, Loss: 0.4154278891427176\n",
      "Epoch 367/1000, Loss: 0.4122091702052525\n",
      "Epoch 368/1000, Loss: 0.40122976899147034\n",
      "Epoch 369/1000, Loss: 0.4054150666509356\n",
      "Epoch 370/1000, Loss: 0.39141603878566195\n",
      "Epoch 371/1000, Loss: 0.3766806891986302\n",
      "Epoch 372/1000, Loss: 0.3784452038151877\n",
      "Epoch 373/1000, Loss: 0.3777741236346109\n",
      "Epoch 374/1000, Loss: 0.3788493573665619\n",
      "Epoch 375/1000, Loss: 0.3552837754998888\n",
      "Epoch 376/1000, Loss: 0.35849183797836304\n",
      "Epoch 377/1000, Loss: 0.33271467685699463\n",
      "Epoch 378/1000, Loss: 0.3381753010409219\n",
      "Epoch 379/1000, Loss: 0.3305957849536623\n",
      "Epoch 380/1000, Loss: 0.5226470232009888\n",
      "Epoch 381/1000, Loss: 0.875416670526777\n",
      "Epoch 382/1000, Loss: 1.1265812175614494\n",
      "Epoch 383/1000, Loss: 1.2871165360723222\n",
      "Epoch 384/1000, Loss: 1.1569641998835973\n",
      "Epoch 385/1000, Loss: 1.012077305998121\n",
      "Epoch 386/1000, Loss: 1.1633198176111494\n",
      "Epoch 387/1000, Loss: 1.2893309508051192\n",
      "Epoch 388/1000, Loss: 1.0777374505996704\n",
      "Epoch 389/1000, Loss: 0.9756206359182086\n",
      "Epoch 390/1000, Loss: 0.836566184248243\n",
      "Epoch 391/1000, Loss: 0.6882817915507725\n",
      "Epoch 392/1000, Loss: 0.6011548382895333\n",
      "Epoch 393/1000, Loss: 0.5214238379682813\n",
      "Epoch 394/1000, Loss: 0.4749458943094526\n",
      "Epoch 395/1000, Loss: 0.4254734494856426\n",
      "Epoch 396/1000, Loss: 0.4113209162439619\n",
      "Epoch 397/1000, Loss: 0.3857898584433964\n",
      "Epoch 398/1000, Loss: 0.3724117577075958\n",
      "Epoch 399/1000, Loss: 0.3548239469528198\n",
      "Epoch 400/1000, Loss: 0.33816137484141756\n",
      "Epoch 401/1000, Loss: 0.32244814719472614\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     73\u001b[0m evaluate_model(model, val_loader, criterion)\n",
      "Cell \u001b[1;32mIn[44], line 29\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_batch\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m     27\u001b[0m     X_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m input_lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((X_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),), outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)  \u001b[38;5;66;03m# Sequence length for each batch element\u001b[39;00m\n\u001b[0;32m     31\u001b[0m target_lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mlen\u001b[39m(y[y \u001b[38;5;241m!=\u001b[39m phoneme_to_index[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m]]) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m y_batch], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)  \u001b[38;5;66;03m# Target sequence length ignoring padding\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bouba\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\acsr-MgaKDfGw-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bouba\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\acsr-MgaKDfGw-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[44], line 15\u001b[0m, in \u001b[0;36mCuedSpeechRNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 15\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlog_softmax(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bouba\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\acsr-MgaKDfGw-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bouba\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\acsr-MgaKDfGw-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bouba\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\acsr-MgaKDfGw-py3.11\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1137\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1145\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Model Definition\n",
    "class CuedSpeechRNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=128, num_layers=2):\n",
    "        super(CuedSpeechRNN, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim + 1)  # +1 for the CTC blank token\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=50):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # Ensure X_batch is 3D: (batch_size, sequence_length, feature_dimension)\n",
    "            if X_batch.dim() == 2:\n",
    "                X_batch = X_batch.unsqueeze(0)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            input_lengths = torch.full((X_batch.size(0),), outputs.size(1), dtype=torch.long)  # Sequence length for each batch element\n",
    "            target_lengths = torch.tensor([len(y[y != phoneme_to_index[' ']]) for y in y_batch], dtype=torch.long)  # Target sequence length ignoring padding\n",
    "\n",
    "            # Compute CTC loss\n",
    "            loss = criterion(outputs.transpose(0, 1), y_batch, input_lengths, target_lengths)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            if X_batch.dim() == 2:\n",
    "                X_batch = X_batch.unsqueeze(0)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            input_lengths = torch.full((X_batch.size(0),), outputs.size(1), dtype=torch.long)  # Sequence length for each batch element\n",
    "            target_lengths = torch.tensor([len(y[y != phoneme_to_index[' ']]) for y in y_batch], dtype=torch.long)  # Target sequence length ignoring padding\n",
    "\n",
    "            val_loss = criterion(outputs.transpose(0, 1), y_batch, input_lengths, target_lengths)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    print(f\"Validation Loss: {total_val_loss/len(val_loader)}\")\n",
    "\n",
    "\n",
    "# Instantiate and Train Model\n",
    "input_dim = X_combined.shape[-1]\n",
    "output_dim = len(phoneme_to_index)\n",
    "model = CuedSpeechRNN(input_dim, output_dim)\n",
    "criterion = nn.CTCLoss(blank=len(phoneme_to_index))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=1000)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.672272205352783\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded training phoneme sequences: [['<start>', 'v', 'w', 'a', 'l', 'a', 'd', 'e', 'b', 'u', 'z^', 'i', '<end>'], ['<start>', 'v', 'w', 'a', 'l', 'a', 'd', 'y', 'f', 'i', 'l', 'e^', 'k', '<end>'], ['<start>', 'l', 'a', 'f', 'o', 'r', 's', 'd', 'y', 'k', 'u', '<end>'], ['<start>', 'd', 'e^', 'k', 'x', 'l', 'x', 't', 'a~', 'b', 'r', 'b', 'a', 'l', 'e', 'z^', 'k', 'u', '<end>'], ['<start>', 'l', 'a', 'f', 'k', 'a', 's', 'o~', 'g', 's', 'a~', 'b', 'l', 'a~', 'z^', 'h', 'i', 'j', 'e^', 's', 'r', 'x~', 'w', 'o', 'k', 'm', 'a', 'n', 'm', 'w', 'e^', '<end>'], ['<start>', 'e^', 'l', 'm', 'e', 'i', 'p', '<end>'], ['<start>', 'l', 'a', 'v', 'e', 's', 'e^', 'l', 'p', 'r', 'e^', 'm', 'i', 'z', 'r', 'l', 'e', 'v', 'j', 'e', '<end>'], ['<start>', 'd', 'o', 'n', 'x~', 'p', 'x', 't', 'i', 'k', 'u', '<end>'], ['<start>', 'l', 'w', 'i', 'p', 'a~', 's', 'a', '<end>'], ['<start>', 'y', 'n', 'r', 'e', 'p', 'o~', 's', 'a~', 'b', 'i', 'g', '<end>'], ['<start>', 'p', 'r', 'e^', 't', 'l', 'h', 'i', 's', 'e^', 'e', 'k', '<end>'], ['<start>', 'x~', 't', 'u', 'r', 'd', 'x', 'm', 'z^', 'i', '<end>'], ['<start>', 'x~', 'f', 'u', 'r', '<end>'], ['<start>', 'h', 'i', 'z^', 'e', 'y', 'i', 't', 'r', 'e^', 'h', 'i', 'l', 'x', 'f', 'o~', 'x~', 'b', 'r', 'x^', 'i', 'ng', 'j', 'u', 'g', 'o^', 's', 'l', 'a', 'v', '<end>'], ['<start>', 'v', 'u', 'z', 'e^', 'k', 'l', '<end>'], ['<start>', 'i', 'l', 'a', 'b', 'r', 'a', 'z', 's^', 'a', 'k', 'z^', 'u', 'r', 'x~', 'p', 'n', 'x', 'a~', 's', 'j', 'e~', 'a', 'v', 'e^', 'k', 'r', 'i', 'f', 'p', 'w', 'e~', 't', '<end>'], ['<start>', 'x~', 'l', 'u', 's', 'e^', 'z^', 'x', 't', 'i', 'm', 'e', 'd', 'j', 'a', 't', 'm', 'a~', 's', 'r', 'l', 'a', 'p', 'x', 't', 'i', 't', 's^', 'e^', 'v', '<end>'], ['<start>', 'i', 'l', 'a', 'd', 'y', 'g', 'u', '<end>'], ['<start>', 'n', 'o', 'a', 'm', 's^', 'm', 's', 'k', 'i', 'b', 'a', 'l', 'j', 'a~', 'k', 'o^', 'r', 'l', 'k', 'l', 'x^', 'b', 's', 'a', '<end>'], ['<start>', 'x', 's', 'w', 'e^', 't', 'k', 'x', 's', 'a', 'p', 'o', 'z', 'e', 'n', 'x', 'x', 'a', 'v', 'z^', 'a', 'm', 'e^', 't', 'g', 'r', 'e^', 'r', 'i', 'd', 'i', 'y', 'l', '<end>'], ['<start>', 't', 'j', 'e~', 't', 'w', 'a', '<end>'], ['<start>', 'i', 'l', 's', 'x', 'g', 'a', 'r', 'a~', 'r', 'a', 'd', 'y', 'f', 'r', 'w', 'a', 'v', 'e^', 'k', 's', 'x', 'b', 'k', 'a', '<end>'], ['<start>', 'i', 'l', 'f', 'e^', 'd', 'e', 'z', 'a', 's^', 'a', '<end>'], ['<start>', 'n', 'o^', 'a', 'l', 'm', 'a', 's', 'j', 'e~', 'k', 'a~', 'p', 'o^', 'k', 'a~', 'p', 'i', 'ng', 'a', 'l', 'a', 'm', 't', '<end>'], ['<start>', 'l', 'e', 'd', 'x', 'k', 'a', 'm', 'j', 'o~', 's', 'x', 's', 'o~', 'x^', 't', 'e', 'd', 'x', 'f', 'a', '<end>'], ['<start>', 'a', 'n', 'i', 's', 'a~', 'n', 'h', 'i', 'l', 'e~', 'd', 'x', 'm', 'e', 'p', 'a', '<end>'], ['<start>', 'm', 'a', 'x', 'm', 'i', 'z', 'e^', 'r', 'u', '<end>']]\n",
      "True training phoneme sequences: [['<start>', 'v', 'w', 'a', 'l', 'a', 'd', 'e', 'b', 'u', 'z^', 'i', '<end>'], ['<start>', 'v', 'w', 'a', 'l', 'a', 'd', 'y', 'f', 'i', 'l', 'e^', 'k', 'r', 'y', '<end>'], ['<start>', 'l', 'a', 'f', 'o', 'r', 's', 'd', 'y', 'k', 'u', '<end>'], ['<start>', 'd', 'e^', 'k', 'x', 'l', 'x', 't', 'a~', 'b', 'u', 'r', 'b', 'a', 'l', 'e', 'z^', 'a~', 'a', 'k', 'u', 'r', '<end>'], ['<start>', 'l', 'a', 'f', 'r', 'i', 'k', 'a', 's', 'o~', 'g', 's', 'a~', 'b', 'a', 'l', 'a~', 'z^', 'h', 'i', 'j', 'e^', 's', 'y', 'r', 'x~', 'w', 'o', 'k', 'm', 'a', 'n', 'm', 'w', 'e^', '<end>'], ['<start>', 'e^', 'l', 'm', 'e', 't', 'r', 'i', 'p', 'a', '<end>'], ['<start>', 'l', 'a', 'v', 'e', 's', 'e^', 'l', 'p', 'r', 'o', 'p', 'r', 'e^', 'm', 'i', 'z', 's', 'y', 'r', 'l', 'e', 'v', 'j', 'e', '<end>'], ['<start>', 'd', 'o', 'n', 'x~', 'p', 'x', 't', 'i', 'k', 'u', '<end>'], ['<start>', 'l', 'w', 'i', 'p', 'a~', 's', 'a', 's', 'a', '<end>'], ['<start>', 'y', 'n', 'r', 'e', 'p', 'o~', 's', 'a~', 'b', 'i', 'g', 'y', '<end>'], ['<start>', 'p', 'r', 'e^', 't', 'l', 'h', 'i', 's', 'e^', 'z', 'e', 'k', 'y', '<end>'], ['<start>', 'x~', 't', 'u', 'r', 'd', 'x', 'm', 'a', 'z^', 'i', '<end>'], ['<start>', 'x~', 'f', 'u', 'r', 't', 'u', 'f', 'y', '<end>'], ['<start>', 'h', 'i', 'z^', 'e', 'z', 'y', 'i', 't', 't', 'r', 'e^', 'h', 'i', 'l', 'x', 's', 'x', 'f', 'o~', 'x~', 'b', 'r', 'x^', 's^', 'i', 'ng', 'ng', 'j', 'u', 'g', 'o^', 's', 'l', 'a', 'v', '<end>'], ['<start>', 'v', 'u', 'z', 'e^', 't', 'e^', 'k', 'k', 'l', 'y', '<end>'], ['<start>', 'i', 'l', 'a', 'b', 'r', 'a', 'z', 's^', 'a', 'k', 'z^', 'u', 'r', 'x~', 'p', 'n', 'x', 'a~', 's', 'j', 'e~', 'a', 'v', 'e^', 'k', 's', 'e', 'g', 'r', 'i', 'f', 'p', 'w', 'e~', 't', 'y', '<end>'], ['<start>', 'x~', 'l', 'u', 's', 'e^', 'z^', 'x', 't', 'e', 'i', 'm', 'e', 'd', 'j', 'a', 't', 'm', 'a~', 's', 'y', 'r', 'l', 'a', 'p', 'x', 't', 'i', 't', 's^', 'e^', 'v', 'r', '<end>'], ['<start>', 'i', 'l', 'a', 'd', 'y', 'g', 'u', '<end>'], ['<start>', 'n', 'o', 'a', 'm', 's^', 'o', 'm', 's', 'k', 'i', 'b', 'a', 'l', 'e^', 'j', 'a~', 'k', 'o^', 'r', 'l', 'x', 'k', 'l', 'x^', 'b', 's', 'x', 's', 'w', 'a', 'r', '<end>'], ['<start>', 'z^', 'x', 's', 'w', 'e^', 't', 'k', 'x', 's', 'a', 'p', 'o', 'y', 'z', 'e', 'n', 'x', 'r', 'x', 's', 'w', 'a', 'v', 'z^', 'a', 'm', 'e^', 's', 'e^', 't', 'g', 'r', 'e^', 'f', 'r', 'i', 'd', 'i', 'k', 'y', 'l', '<end>'], ['<start>', 't', 'j', 'e~', 't', 'w', 'a', 'a', 's', 'i', '<end>'], ['<start>', 'i', 'l', 's', 'x', 'g', 'a', 'r', 'a~', 't', 'i', 'r', 'a', 'd', 'y', 'f', 'r', 'w', 'a', 'a', 'v', 'e^', 'k', 's', 'x', 'b', 'o~', 'k', 'a', 'p', 'y', 's^', 'o~', '<end>'], ['<start>', 'i', 'l', 'f', 'e^', 'd', 'e', 'z', 'a', 's^', 'a', '<end>'], ['<start>', 'n', 'o^', 'd', 'a', 'l', 'm', 'a', 's', 'j', 'e~', 'k', 'a~', 'p', 'e^', 'o^', 'k', 'a~', 'p', 'i', 'ng', 'ng', 'a', 'l', 'a', 'm', 'o~', 't', 'a', '<end>'], ['<start>', 'l', 'e', 'd', 'x', 'k', 'a', 'm', 'j', 'o~', 's', 'x', 's', 'o~', 'x^', 'r', 't', 'e', 'd', 'x', 'f', 'a', 's', '<end>'], ['<start>', 'a', 'n', 'i', 's', 'a~', 'n', 'h', 'i', 'l', 'w', 'e~', 'd', 'x', 'm', 'e', 'p', 'a', 'r', 'a~', '<end>'], ['<start>', 'm', 'a', 's^', 'x', 'm', 'i', 'z', 'e^', 'r', 'u', 's', 'i', '<end>']]\n",
      "Decoded validation phoneme sequences: [['<start>', 'l', 'a', 'd', 'i', 'j', 'x', 'x', 'k', 'a', 'l', 'x', 'e^', 'e', 'l', '<end>'], ['<start>', 'x', '<end>'], ['<start>', 'l', 'a', 'x', 'u', 'k', 'i', 'ng', 'a', 's', 'l', 'k', 'v', 'a', 'a', '<end>']]\n",
      "True validation phoneme sequences: [['<start>', 's', 'x', 'f', 'u', 'o', 'r', 'd', 'i', 'n', 'e^', 'r', 'f', 'i', 's^', 'l', 'x', 't', 'y', 'r', 'b', 'a~', 'e~', 'd', 'j', 'e~', 'd', 'a~', 'l', 'x', 'b', 'e~', 'o', 'p', 's', 'j', 'o^', 'n', 'e^', 'l', '<end>'], ['<start>', 's^', 'x', 'v', 'a', 'l', 'j', 'e', 'd', 'y', 'g', 'e', '<end>'], ['<start>', 'l', 'x', 'z^', 'e', 'o^', 'l', 'o', 'g', 't', 'r', 'u', 'v', 'f', 'i', 'n', 'a', 'l', 'm', 'a~', 'l', 'a', 'u', 'j', 'a~', 'v', 'r', 'a', 'k', 'd', 'a~', 'l', 'x', 'g', 'a', 'v', 'd', 'x', 'p', 'o^', '<end>']]\n"
     ]
    }
   ],
   "source": [
    "def greedy_decoder(output, blank):\n",
    "    \"\"\"\n",
    "    Decode model outputs using a greedy decoder.\n",
    "\n",
    "    Args:\n",
    "        output (torch.Tensor): Model outputs of shape (batch_size, sequence_length, num_classes).\n",
    "        blank (int): Index of the blank token.\n",
    "\n",
    "    Returns:\n",
    "        list: List of decoded sequences.\n",
    "    \"\"\"\n",
    "    arg_maxes = torch.argmax(output, dim=2)  # Get the most likely class for each time step\n",
    "    decodes = []\n",
    "    for args in arg_maxes:\n",
    "        decode = []\n",
    "        previous_idx = None\n",
    "        for index in args:\n",
    "            if index != blank and (previous_idx is None or index != previous_idx):\n",
    "                decode.append(index.item())  # Append non-blank and non-repeated tokens\n",
    "            previous_idx = index\n",
    "        decodes.append(decode)\n",
    "    return decodes\n",
    "\n",
    "\n",
    "def decode_loader(model, loader, blank, index_to_phoneme):\n",
    "    \"\"\"\n",
    "    Decode outputs for all batches in a DataLoader and return both decoded and true sequences.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        loader (torch.utils.data.DataLoader): DataLoader containing input data and labels.\n",
    "        blank (int): Index of the blank token.\n",
    "        index_to_phoneme (dict): Mapping from indices to phonemes.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (decoded_sequences, true_sequences), where:\n",
    "            - decoded_sequences: List of decoded phoneme sequences.\n",
    "            - true_sequences: List of true phoneme sequences.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_decoded_sequences = []\n",
    "    all_true_sequences = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for X_batch, y_batch in loader:  # Iterate over batches (X_batch: inputs, y_batch: labels)\n",
    "            outputs = model(X_batch)  # Get model predictions\n",
    "            decoded_phoneme_sequences = greedy_decoder(outputs, blank=blank)  # Decode outputs\n",
    "            decoded_phonemes = [[index_to_phoneme[idx] for idx in sequence] for sequence in decoded_phoneme_sequences]  # Convert indices to phonemes\n",
    "            all_decoded_sequences.extend(decoded_phonemes)  # Add to the list of decoded sequences\n",
    "\n",
    "            # Convert true labels to phoneme sequences\n",
    "            true_phoneme_sequences = [[index_to_phoneme[idx.item()] for idx in sequence if idx != blank and \n",
    "                                       index_to_phoneme[idx.item()] != \" \"] for sequence in y_batch]\n",
    "            all_true_sequences.extend(true_phoneme_sequences)  # Add to the list of true sequences\n",
    "\n",
    "    return all_decoded_sequences, all_true_sequences\n",
    "\n",
    "\n",
    "# Example usage\n",
    "blank_token = len(phoneme_to_index)  # Index of the blank token\n",
    "decoded_train_sequences, true_train_sequences = decode_loader(model, train_loader, blank_token, index_to_phoneme)\n",
    "decoded_val_sequences, true_val_sequences = decode_loader(model, val_loader, blank_token, index_to_phoneme)\n",
    "\n",
    "# Print results\n",
    "print(\"Decoded training phoneme sequences:\", decoded_train_sequences)\n",
    "print(\"True training phoneme sequences:\", true_train_sequences)\n",
    "print(\"Decoded validation phoneme sequences:\", decoded_val_sequences)\n",
    "print(\"True validation phoneme sequences:\", true_val_sequences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PER (jiwer): 0.15097690941385436 1 - PER:  0.8490230905861457\n",
      "Validation PER (jiwer): 0.7789473684210526 1 - PER:  0.2210526315789474\n"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "\n",
    "def calculate_per_with_jiwer(decoded_sequences, true_sequences):\n",
    "    \"\"\"\n",
    "    Calculate the Phoneme Error Rate (PER) using jiwer.\n",
    "\n",
    "    Args:\n",
    "        decoded_sequences (list): List of decoded phoneme sequences.\n",
    "        true_sequences (list): List of true phoneme sequences.\n",
    "\n",
    "    Returns:\n",
    "        float: Phoneme Error Rate (PER).\n",
    "    \"\"\"\n",
    "    # Convert phoneme sequences to space-separated strings\n",
    "    decoded_str = [\" \".join(seq) for seq in decoded_sequences]\n",
    "    true_str = [\" \".join(seq) for seq in true_sequences]\n",
    "\n",
    "    # Calculate PER using jiwer\n",
    "    per = jiwer.wer(true_str, decoded_str)\n",
    "    return per\n",
    "\n",
    "# Example usage\n",
    "train_per = calculate_per_with_jiwer(decoded_train_sequences, true_train_sequences)\n",
    "val_per = calculate_per_with_jiwer(decoded_val_sequences, true_val_sequences)\n",
    "\n",
    "print(\"Training PER (jiwer):\", train_per, \"1 - PER: \", 1 - train_per)\n",
    "print(\"Validation PER (jiwer):\", val_per, \"1 - PER: \", 1 - val_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acsr-MgaKDfGw-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
